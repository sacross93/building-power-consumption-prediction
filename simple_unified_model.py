#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìµœì¢… ê°œì„  ë²„ì „: test.py ì°¸ê³ í•œ ì²´ê³„ì  ì ‘ê·¼ë²•
ê¹”ë”í•œ ë°ì´í„° í”Œë¡œìš° + ê±´ë¬¼ë³„ ê°œë³„ ëª¨ë¸ + ì ì ˆí•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
"""
import pandas as pd
import numpy as np
import lightgbm as lgb
import xgboost as xgb
import holidays
import warnings
warnings.filterwarnings('ignore')

def smape(y_true, y_pred):
    """SMAPE ê³„ì‚° (test.pyì™€ ë™ì¼)"""
    epsilon = 1e-10
    numerator = 2 * np.abs(y_pred - y_true)
    denominator = np.abs(y_true) + np.abs(y_pred) + epsilon
    return np.mean(numerator / denominator) * 100

def create_features(df):
    """ì²´ê³„ì ì¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (test.py ê¸°ë°˜ + ê°œì„ )"""
    df = df.sort_values(by=['ê±´ë¬¼ë²ˆí˜¸', 'ì¼ì‹œ']).reset_index(drop=True)
    
    # 1. ì‹œê°„ ê´€ë ¨ í”¼ì²˜
    df['month'] = df['ì¼ì‹œ'].dt.month
    df['day'] = df['ì¼ì‹œ'].dt.day
    df['hour'] = df['ì¼ì‹œ'].dt.hour
    df['weekday'] = df['ì¼ì‹œ'].dt.weekday
    df['is_weekend'] = (df['weekday'] >= 5).astype(int)
    
    # ì£¼ê¸°ì„± ì¸ì½”ë”©
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)
    df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7)
    
    # 2. í•œêµ­ ê³µíœ´ì¼ í”¼ì²˜ (test.pyì—ì„œ ê°€ì ¸ì˜´)
    kr_holidays = holidays.KR(years=[2024])
    df['is_holiday'] = df['ì¼ì‹œ'].dt.date.apply(lambda x: 1 if x in kr_holidays else 0).astype(int)
    
    # 3. ì˜¨ë„-ìŠµë„ ë¶ˆì¾Œì§€ìˆ˜ (THI) - test.pyì—ì„œ ê°€ì ¸ì˜´
    df['THI'] = 9/5 * df['ê¸°ì˜¨(Â°C)'] - 0.55 * (1 - df['ìŠµë„(%)']/100) * (9/5 * df['ê¸°ì˜¨(Â°C)'] - 26) + 32
    
    # 4. ë‚ ì”¨ ìƒí˜¸ì‘ìš© í”¼ì²˜
    df['temp_x_hour'] = df['ê¸°ì˜¨(Â°C)'] * df['hour']
    df['humidity_x_hour'] = df['ìŠµë„(%)'] * df['hour']
    df['temp_x_humidity'] = df['ê¸°ì˜¨(Â°C)'] * df['ìŠµë„(%)']
    
    # 5. ë‚ ì”¨ ì´ë™ í†µê³„ (6ì‹œê°„ ìœˆë„ìš°)
    df['temp_rolling_mean_6'] = df.groupby('ê±´ë¬¼ë²ˆí˜¸')['ê¸°ì˜¨(Â°C)'].transform(
        lambda x: x.rolling(window=6, min_periods=1).mean())
    df['temp_rolling_std_6'] = df.groupby('ê±´ë¬¼ë²ˆí˜¸')['ê¸°ì˜¨(Â°C)'].transform(
        lambda x: x.rolling(window=6, min_periods=1).std()).fillna(0)
    df['humidity_rolling_mean_6'] = df.groupby('ê±´ë¬¼ë²ˆí˜¸')['ìŠµë„(%)'].transform(
        lambda x: x.rolling(window=6, min_periods=1).mean())
    
    # 6. ì‹œì°¨ ë³€ìˆ˜ (Data Leakage ë°©ì§€)
    if 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)' in df.columns:
        lags = [24, 48, 168]  # 1ì¼, 2ì¼, 1ì£¼ì¼
        for lag in lags:
            df[f'power_lag_{lag}'] = df.groupby('ê±´ë¬¼ë²ˆí˜¸')['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].transform(
                lambda x: x.shift(lag))
            df[f'temp_lag_{lag}'] = df.groupby('ê±´ë¬¼ë²ˆí˜¸')['ê¸°ì˜¨(Â°C)'].transform(
                lambda x: x.shift(lag))
    
    # 7. ê±´ë¬¼ ë©´ì  ë¹„ìœ¨
    df['area_ratio'] = df['ëƒ‰ë°©ë©´ì (m2)'] / (df['ì—°ë©´ì (m2)'] + 1e-6)
    
    return df

def main():
    print("ğŸš€ ìµœì¢… ê°œì„ : test.py ì°¸ê³ í•œ ì²´ê³„ì  ì ‘ê·¼ë²•")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë”©
    print("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
    train_df = pd.read_csv('data/train.csv', parse_dates=['ì¼ì‹œ'])
    test_df = pd.read_csv('data/test.csv', parse_dates=['ì¼ì‹œ'])
    building_info_df = pd.read_csv('data/building_info.csv')
    print("âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ")

    # 2. ê±´ë¬¼ ì •ë³´ ì „ì²˜ë¦¬
    print("ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    numeric_cols = ['ì—°ë©´ì (m2)', 'ëƒ‰ë°©ë©´ì (m2)', 'íƒœì–‘ê´‘ìš©ëŸ‰(kW)', 'ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)']
    for col in numeric_cols:
        building_info_df[col] = building_info_df[col].replace('-', '0').astype(float)

    # 3. ë°ì´í„° ë³‘í•©
    train_df = pd.merge(train_df, building_info_df, on='ê±´ë¬¼ë²ˆí˜¸', how='left')
    test_df = pd.merge(test_df, building_info_df, on='ê±´ë¬¼ë²ˆí˜¸', how='left')
    
    # test ë°ì´í„°ì˜ ì „ë ¥ì†Œë¹„ëŸ‰ì€ NaNìœ¼ë¡œ ì´ˆê¸°í™”
    test_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'] = np.nan
    
    # ì „ì²´ ë°ì´í„° í†µí•©í•˜ì—¬ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    combined_df = pd.concat([train_df, test_df], ignore_index=True)
    print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")

    # 4. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    print("âš™ï¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì¤‘...")
    combined_df = create_features(combined_df)
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
    combined_df['ê±´ë¬¼ë²ˆí˜¸'] = combined_df['ê±´ë¬¼ë²ˆí˜¸'].astype('category')
    combined_df['ê±´ë¬¼ìœ í˜•'] = combined_df['ê±´ë¬¼ìœ í˜•'].astype('category')
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
    train_processed_df = combined_df[~combined_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].isna()].copy()
    test_processed_df = combined_df[combined_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].isna()].copy()
    print("âœ… í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ")

    # 5. í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ ì •ì˜ (test.py ìŠ¤íƒ€ì¼)
    features = [
        'ê±´ë¬¼ë²ˆí˜¸', 'ê¸°ì˜¨(Â°C)', 'í’ì†(m/s)', 'ìŠµë„(%)',
        'ì—°ë©´ì (m2)', 'ëƒ‰ë°©ë©´ì (m2)', 'íƒœì–‘ê´‘ìš©ëŸ‰(kW)', 'ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)',
        'month', 'day', 'hour', 'weekday', 'is_weekend', 'is_holiday',
        'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'weekday_sin', 'weekday_cos',
        'THI', 'temp_x_hour', 'humidity_x_hour', 'temp_x_humidity', 'area_ratio',
        'temp_rolling_mean_6', 'temp_rolling_std_6', 'humidity_rolling_mean_6',
        'power_lag_24', 'temp_lag_24', 'power_lag_48', 'temp_lag_48', 'power_lag_168', 'temp_lag_168'
    ]
    
    categorical_features_for_model = ['ê±´ë¬¼ë²ˆí˜¸']
    
    print(f"ğŸ“ˆ ì‚¬ìš©í•  í”¼ì²˜ ìˆ˜: {len(features)}ê°œ")
    print(f"ğŸ“Š í•™ìŠµ ë°ì´í„°: {train_processed_df.shape}")
    print(f"ğŸ¢ ê±´ë¬¼ ìœ í˜•: {train_processed_df['ê±´ë¬¼ìœ í˜•'].nunique()}ê°œ")

    # 6. ê±´ë¬¼ ìœ í˜•ë³„ ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦
    print("\nğŸ—ï¸ ê±´ë¬¼ ìœ í˜•ë³„ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    
    building_types = train_processed_df['ê±´ë¬¼ìœ í˜•'].unique()
    total_predictions = []
    total_smape_score = 0
    building_results = []
    
    for b_type in building_types:
        print(f"\nğŸ¢ {b_type} ìœ í˜• ëª¨ë¸ í•™ìŠµ...")
        
        type_train_df = train_processed_df[train_processed_df['ê±´ë¬¼ìœ í˜•'] == b_type].copy()
        
        # ì‹œê°„ ê¸°ë°˜ ë¶„í•  (test.py ë°©ì‹)
        split_date = pd.to_datetime('2024-08-18 00:00:00')
        train_val_df = type_train_df[type_train_df['ì¼ì‹œ'] < split_date]
        valid_df = type_train_df[type_train_df['ì¼ì‹œ'] >= split_date]
        
        if len(valid_df) == 0:
            print(f"   âš ï¸ ê²€ì¦ ë°ì´í„° ì—†ìŒ - ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ")
            train_val_df = type_train_df
            valid_df = type_train_df.tail(100)  # ì„ì‹œ ê²€ì¦ìš©

        X_train_val = train_val_df[features]
        y_train_val = train_val_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
        X_valid = valid_df[features]
        y_valid = valid_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
        
        # XGBoostë¥¼ ìœ„í•´ ë²”ì£¼í˜• ë°ì´í„° ì²˜ë¦¬
        X_train_val_xgb = X_train_val.copy()
        X_valid_xgb = X_valid.copy()
        X_train_val_xgb['ê±´ë¬¼ë²ˆí˜¸'] = X_train_val_xgb['ê±´ë¬¼ë²ˆí˜¸'].cat.codes
        X_valid_xgb['ê±´ë¬¼ë²ˆí˜¸'] = X_valid_xgb['ê±´ë¬¼ë²ˆí˜¸'].cat.codes
        
        print(f"   ğŸ“Š í•™ìŠµ: {len(train_val_df)}ê°œ, ê²€ì¦: {len(valid_df)}ê°œ")

        # XGBoost íŒŒë¼ë¯¸í„° (ë©”ì¸ ëª¨ë¸)
        xgb_params = {
            'objective': 'reg:absoluteerror',
            'random_state': 42,
            'n_estimators': 2000,
            'learning_rate': 0.02,
            'max_depth': 8,
            'subsample': 0.7,
            'colsample_bytree': 0.7,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1,
            'verbosity': 0
        }
        
        # LightGBM íŒŒë¼ë¯¸í„° (ì•™ìƒë¸”ìš©)
        lgb_params = {
            'objective': 'regression_l1',
            'random_state': 42,
            'n_estimators': 2000,
            'learning_rate': 0.02,
            'num_leaves': 32,
            'max_depth': 8,
            'colsample_bytree': 0.7,
            'subsample': 0.7,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1,
            'verbose': -1
        }
        
        # 1. XGBoost ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦
        print(f"   ğŸ”¹ XGBoost ëª¨ë¸ í•™ìŠµ...")
        xgb_model = xgb.XGBRegressor(**xgb_params)
        
        # XGBoost í›ˆë ¨ (early stopping ì—†ì´)
        xgb_model.fit(X_train_val_xgb, y_train_val)
        
        xgb_best_iter = xgb_model.n_estimators  # ì „ì²´ ë°˜ë³µ ì‚¬ìš©
        xgb_valid_preds = xgb_model.predict(X_valid_xgb)
        xgb_valid_preds = np.maximum(xgb_valid_preds, 0)
        xgb_smape = smape(y_valid.values, xgb_valid_preds)
        
        # 2. LightGBM ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦
        print(f"   ğŸ”¹ LightGBM ëª¨ë¸ í•™ìŠµ...")
        lgb_model = lgb.LGBMRegressor(**lgb_params)
        
        lgb_model.fit(
            X_train_val, y_train_val, 
            eval_set=[(X_valid, y_valid)], 
            callbacks=[lgb.early_stopping(100, verbose=False)], 
            categorical_feature=categorical_features_for_model
        )
        
        lgb_best_iter = lgb_model.best_iteration_
        lgb_valid_preds = lgb_model.predict(X_valid, num_iteration=lgb_best_iter)
        lgb_valid_preds = np.maximum(lgb_valid_preds, 0)
        lgb_smape = smape(y_valid.values, lgb_valid_preds)
        
        # 3. ì•™ìƒë¸” ì˜ˆì¸¡ (XGBoost 70% + LightGBM 30%)
        ensemble_preds = 0.7 * xgb_valid_preds + 0.3 * lgb_valid_preds
        ensemble_smape = smape(y_valid.values, ensemble_preds)
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
        best_smape = min(xgb_smape, lgb_smape, ensemble_smape)
        if best_smape == xgb_smape:
            best_model_name = "XGBoost"
            best_iter = xgb_best_iter
            type_smape = xgb_smape
        elif best_smape == lgb_smape:
            best_model_name = "LightGBM"
            best_iter = lgb_best_iter
            type_smape = lgb_smape
        else:
            best_model_name = "Ensemble"
            best_iter = max(xgb_best_iter, lgb_best_iter)
            type_smape = ensemble_smape
        
        total_smape_score += type_smape
        building_results.append((b_type, type_smape, best_iter, len(type_train_df), best_model_name))
        
        print(f"   ğŸ“Š XGBoost SMAPE: {xgb_smape:.2f}% (ë°˜ë³µ: {xgb_best_iter})")
        print(f"   ğŸ“Š LightGBM SMAPE: {lgb_smape:.2f}% (ë°˜ë³µ: {lgb_best_iter})")
        print(f"   ğŸ“Š Ensemble SMAPE: {ensemble_smape:.2f}%")
        print(f"   ğŸ† ìµœê³  ì„±ëŠ¥: {best_model_name} ({type_smape:.2f}%)")

        # ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ
        X_train_full = type_train_df[features]
        y_train_full = type_train_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
        
        # XGBoostìš© ë°ì´í„° ì¤€ë¹„
        X_train_full_xgb = X_train_full.copy()
        X_train_full_xgb['ê±´ë¬¼ë²ˆí˜¸'] = X_train_full_xgb['ê±´ë¬¼ë²ˆí˜¸'].cat.codes
        
        # XGBoost ìµœì¢… ëª¨ë¸
        final_xgb_params = xgb_params.copy()
        final_xgb_params['n_estimators'] = xgb_best_iter
        final_xgb_model = xgb.XGBRegressor(**final_xgb_params)
        final_xgb_model.fit(X_train_full_xgb, y_train_full)
        
        # LightGBM ìµœì¢… ëª¨ë¸
        final_lgb_params = lgb_params.copy()
        final_lgb_params['n_estimators'] = lgb_best_iter
        final_lgb_model = lgb.LGBMRegressor(**final_lgb_params)
        final_lgb_model.fit(X_train_full, y_train_full, categorical_feature=categorical_features_for_model)
        
        # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
        type_test_df = test_processed_df[test_processed_df['ê±´ë¬¼ìœ í˜•'] == b_type]
        
        if not type_test_df.empty:
            X_test = type_test_df[features]
            
            # XGBoostìš© í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
            X_test_xgb = X_test.copy()
            X_test_xgb['ê±´ë¬¼ë²ˆí˜¸'] = X_test_xgb['ê±´ë¬¼ë²ˆí˜¸'].cat.codes
            
            # XGBoost ì˜ˆì¸¡
            xgb_test_preds = final_xgb_model.predict(X_test_xgb)
            xgb_test_preds = np.maximum(xgb_test_preds, 0)
            
            # LightGBM ì˜ˆì¸¡
            lgb_test_preds = final_lgb_model.predict(X_test)
            lgb_test_preds = np.maximum(lgb_test_preds, 0)
            
            # ì•™ìƒë¸” ì˜ˆì¸¡ (ê²€ì¦ì—ì„œ ìµœê³  ì„±ëŠ¥ì´ì—ˆë˜ ë°©ì‹ ì‚¬ìš©)
            if best_model_name == "XGBoost":
                final_preds = xgb_test_preds
            elif best_model_name == "LightGBM":
                final_preds = lgb_test_preds
            else:  # Ensemble
                final_preds = 0.7 * xgb_test_preds + 0.3 * lgb_test_preds
            
            temp_submission = pd.DataFrame({
                'num_date_time': type_test_df['num_date_time'], 
                'answer': final_preds
            })
            total_predictions.append(temp_submission)
            print(f"   ğŸ“¤ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡: {len(final_preds)}ê°œ ({best_model_name} ë°©ì‹)")

    # 7. ê²°ê³¼ ì·¨í•©
    print(f"\nğŸ¯ ê±´ë¬¼ë³„ ì„±ëŠ¥ ê²°ê³¼:")
    print("=" * 80)
    for b_type, smape_score, best_iter, data_count, best_model in building_results:
        print(f"   {b_type:20s}: SMAPE {smape_score:6.2f}% (ë°ì´í„°: {data_count:5d}ê°œ, ë°˜ë³µ: {best_iter:4d}, ëª¨ë¸: {best_model})")
    
    avg_smape = total_smape_score / len(building_types)
    print("=" * 80)
    print(f"ğŸ† í‰ê·  ê²€ì¦ SMAPE: {avg_smape:.2f}%")
    print("=" * 80)

    # 8. ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„±
    print("\nğŸ“‹ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    final_submission = pd.concat(total_predictions, ignore_index=True)
    
    # sample_submissionê³¼ ë§ì¶¤
    sample_submission = pd.read_csv('data/sample_submission.csv')
    sample_submission = sample_submission.drop(columns=['answer'])
    final_submission = pd.merge(sample_submission, final_submission, on='num_date_time', how='left')
    
    # ê²°ì¸¡ê°’ ì²˜ë¦¬ (í˜¹ì‹œ ëˆ„ë½ëœ ë°ì´í„°ê°€ ìˆë‹¤ë©´)
    if final_submission['answer'].isna().sum() > 0:
        print(f"   âš ï¸ ê²°ì¸¡ê°’ {final_submission['answer'].isna().sum()}ê°œ ë°œê²¬ - í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´")
        final_submission['answer'].fillna(final_submission['answer'].mean(), inplace=True)
    
    final_submission.to_csv('submission_final.csv', index=False)
    
    print(f"âœ… submission_final.csv ì €ì¥ ì™„ë£Œ! ({len(final_submission)}í–‰)")
    print(f"ğŸ“Š ì˜ˆì¸¡ê°’ ë²”ìœ„: {final_submission['answer'].min():.1f} ~ {final_submission['answer'].max():.1f}")
    print(f"ğŸ“ˆ ì˜ˆì¸¡ê°’ í‰ê· : {final_submission['answer'].mean():.1f}")
    
    # ê°œì„  íš¨ê³¼ ìš”ì•½
    print(f"\nğŸ“Š ìµœì¢… ê°œì„  íš¨ê³¼:")
    print(f"   ğŸ”¹ í”¼ì²˜ ìˆ˜: {len(features)}ê°œ (ì ì ˆí•œ ìˆ˜ì¤€)")
    print(f"   ğŸ”¹ í•œêµ­ ê³µíœ´ì¼: ì ìš©ë¨")
    print(f"   ğŸ”¹ THI ë¶ˆì¾Œì§€ìˆ˜: ì ìš©ë¨")
    print(f"   ğŸ”¹ ê±´ë¬¼ë³„ ê°œë³„ ëª¨ë¸: {len(building_types)}ê°œ ìœ í˜•")
    print(f"   ğŸ”¹ ì‹œê°„ ê¸°ë°˜ ê²€ì¦: ì ìš©ë¨")
    print(f"   ğŸ”¹ Early Stopping: ì ìš©ë¨")

if __name__ == "__main__":
    main() 