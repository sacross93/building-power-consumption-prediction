# -*- coding: utf-8 -*-
"""
Energy Consumption Forecast v9 - Optuna + GPU Support
-----------------------------------------------------
â€¢ ë©´ì  ì •ê·œí™”(log1p(kWh / ì—°ë©´ì ))ë¡œ ëª©í‘œë³€ìˆ˜ ìŠ¤ì¼€ì¼ ê°œì„ 
â€¢ ê²°ì¸¡ ì¸ë””ì¼€ì´í„°(íƒœì–‘ê´‘/ESS/PCS) ì¶”ê°€
â€¢ ìƒˆë¡œìš´ ë‚ ì”¨ íŒŒìƒ í”¼ì²˜(Dew Point, Heat Index, THI_diff_24h)
â€¢ ê±´ë¬¼ë³„ ê°œë³„ Optuna ìµœì í™” + LightGBM/XGBoost ì•™ìƒë¸”
â€¢ GPU ê°€ì† ì§€ì› (--gpu í”Œë˜ê·¸)
â€¢ submission.csv ë§¤ ì‹¤í–‰ë§ˆë‹¤ ë®ì–´ì“°ê¸°
"""
import argparse
from pathlib import Path
import warnings
import os
import numpy as np
import pandas as pd
import holidays
import lightgbm as lgb
import xgboost as xgb
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import TimeSeriesSplit
import optuna
warnings.filterwarnings("ignore")

# GPU ê°•ì œ ì‚¬ìš© ì„¤ì • (GPU #3)
os.environ["CUDA_VISIBLE_DEVICES"] = "3"  # GPU 3ë²ˆë§Œ ì‚¬ìš©
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["LIGHTGBM_GPU"] = "1"  # LightGBM GPU ê°•ì œ
os.environ["CUDA_LAUNCH_BLOCKING"] = "1"  # CUDA ë™ê¸°í™”

# Optuna ë¡œê¹… ì–µì œ
optuna.logging.set_verbosity(optuna.logging.WARNING)

KR_HOLIDAYS = holidays.KR()
SEED = 42

###########################################################
# GPU Detection & Setup
###########################################################

def check_gpu_support():
    """GPU ì§€ì› ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ì„±ëŠ¥ ì •ë³´"""
    lgb_gpu = False
    xgb_gpu = False
    
    # LightGBM GPU ì‹¤ì œ í•™ìŠµ í…ŒìŠ¤íŠ¸ (GPU 3ë²ˆ)
    try:
        import numpy as np
        X_test = np.random.rand(100, 5)
        y_test = np.random.rand(100)
        lgb_test = lgb.LGBMRegressor(
            device="gpu", 
            gpu_platform_id=0,
            gpu_device_id=0,  # CUDA_VISIBLE_DEVICES=3ì´ë¯€ë¡œ 0ë²ˆì´ GPU 3ë²ˆ
            max_bin=255,
            n_estimators=50,  # ë” ë§ì´ í…ŒìŠ¤íŠ¸
            num_threads=1,
            force_col_wise=True,
            verbose=-1
        )
        lgb_test.fit(X_test, y_test)
        lgb_gpu = True
        print("âœ… LightGBM GPU #3 support confirmed (training test passed)")
    except Exception as e:
        print(f"âŒ LightGBM GPU #3 failed: {str(e)[:50]}... - using CPU")
    
    # XGBoost GPU ì‹¤ì œ í•™ìŠµ í…ŒìŠ¤íŠ¸ (GPU 3ë²ˆ)
    try:
        import numpy as np
        X_test = np.random.rand(100, 5)
        y_test = np.random.rand(100)
        xgb_test = xgb.XGBRegressor(
            tree_method="gpu_hist", 
            gpu_id=0,  # CUDA_VISIBLE_DEVICES=3ì´ë¯€ë¡œ 0ë²ˆì´ GPU 3ë²ˆ
            max_bin=256,
            n_estimators=50,  # ë” ë§ì´ í…ŒìŠ¤íŠ¸
            predictor="gpu_predictor",
            verbosity=0
        )
        xgb_test.fit(X_test, y_test)
        xgb_gpu = True
        print("âœ… XGBoost GPU #3 support confirmed (training test passed)")
    except Exception as e:
        print(f"âŒ XGBoost GPU #3 failed: {str(e)[:50]}... - using CPU")
    
    # GPU ë©”ëª¨ë¦¬ ì •ë³´ (GPU 3ë²ˆ)
    try:
        import pynvml
        pynvml.nvmlInit()
        handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # CUDA_VISIBLE_DEVICES=3ì´ë¯€ë¡œ 0ë²ˆì´ GPU 3ë²ˆ
        info = pynvml.nvmlDeviceGetMemoryInfo(handle)
        total = info.total // 1024**2  # MB
        free = info.free // 1024**2
        print(f"ğŸš€ GPU #3 Memory: {free}MB free / {total}MB total")
        if free > 4000:  # 4GB ì´ìƒ
            print("ğŸ’ª High GPU memory available - enabling intensive mode")
    except:
        print("ğŸ“Š GPU #3 memory info not available")
    
    if not lgb_gpu or not xgb_gpu:
        print("âŒ GPU requirements not met:")
        print(f"   LightGBM GPU: {'âœ…' if lgb_gpu else 'âŒ'}")
        print(f"   XGBoost GPU: {'âœ…' if xgb_gpu else 'âŒ'}")
        print("ğŸš« Both GPUs must be available for this script!")
        raise RuntimeError("GPU requirement not satisfied. Cannot proceed.")
    
    print("ğŸ¯ All GPU requirements satisfied - proceeding with full GPU mode")
    return lgb_gpu, xgb_gpu

###########################################################
# Metric
###########################################################

def smape_np(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    eps = 1e-8
    y_pred = np.maximum(y_pred, 0)
    return np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + eps)) * 100

###########################################################
# Feature Engineering Helpers
###########################################################

def add_time_features(df: pd.DataFrame) -> pd.DataFrame:
    dt = df["ì¼ì‹œ"]
    df["month"] = dt.dt.month
    df["day"] = dt.dt.day
    df["hour"] = dt.dt.hour
    df["weekday"] = dt.dt.weekday
    df["is_weekend"] = (df["weekday"] >= 5).astype(int)
    df["is_holiday"] = dt.dt.date.map(lambda d: int(d in KR_HOLIDAYS))
    # Fourier
    df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24)
    df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24)
    df["month_sin"] = np.sin(2 * np.pi * df["month"] / 12)
    df["month_cos"] = np.cos(2 * np.pi * df["month"] / 12)
    df["weekday_sin"] = np.sin(2 * np.pi * df["weekday"] / 7)
    df["weekday_cos"] = np.cos(2 * np.pi * df["weekday"] / 7)
    return df

def add_weather_features(df: pd.DataFrame) -> pd.DataFrame:
    df["THI"] = 9/5 * df["ê¸°ì˜¨(Â°C)"] - 0.55 * (1 - df["ìŠµë„(%)"] / 100) * (9/5 * df["ê¸°ì˜¨(Â°C)"] - 26) + 32
    # New
    df["dew_point"] = df["ê¸°ì˜¨(Â°C)"] - (100 - df["ìŠµë„(%)"]) / 5
    df["heat_index"] = 0.5 * (df["ê¸°ì˜¨(Â°C)"] + 61.0 + (df["ê¸°ì˜¨(Â°C)"] - 68.0) * 1.2 + df["ìŠµë„(%)"] * 0.094)
    df["THI_diff_24h"] = df.groupby("ê±´ë¬¼ë²ˆí˜¸")["THI"].diff(24)
    # ì˜¨ë„ ë³€í™”ëŸ‰
    df["temp_diff_1h"] = df.groupby("ê±´ë¬¼ë²ˆí˜¸")["ê¸°ì˜¨(Â°C)"].diff(1)
    df["temp_diff_6h"] = df.groupby("ê±´ë¬¼ë²ˆí˜¸")["ê¸°ì˜¨(Â°C)"].diff(6)
    return df

###########################################################
# Optuna Objectives
###########################################################

def lgb_objective(trial, X_tr, y_tr, X_val, y_val, cat_cols, use_gpu=False):
    params = {
        "objective": "regression_l1",
        "random_state": SEED,
        "learning_rate": trial.suggest_float("lr", 0.01, 0.1, log=True),
        "num_leaves": trial.suggest_int("num_leaves", 31, 256),  # ì•ˆì •ì ì¸ ë²”ìœ„
        "subsample": trial.suggest_float("subsample", 0.6, 1.0),
        "colsample_bytree": trial.suggest_float("colsample", 0.6, 1.0),
        "min_data_in_leaf": trial.suggest_int("min_leaf", 5, 100),
        "reg_alpha": trial.suggest_float("ra", 1e-8, 10.0, log=True),
        "reg_lambda": trial.suggest_float("rl", 1e-8, 10.0, log=True),
        "n_estimators": 1000,  # ì•ˆì •ì ì¸ ìˆ˜ëŸ‰
        "verbose": -1,
        "num_threads": 1,  # GPU ì‚¬ìš© ì‹œ ìŠ¤ë ˆë“œ ì œí•œ
        "force_col_wise": True,  # GPU ìµœì í™”
    }
    
    if not use_gpu:
        raise RuntimeError("ğŸš« GPU mode required! Use --gpu flag or remove --gpu to allow CPU")
    
    # GPU ì „ìš© ì„¤ì • - ê°•ì œ GPU #3 ì‚¬ìš©
    params["device"] = "gpu" 
    params["gpu_use_dp"] = True
    params["gpu_platform_id"] = 0
    params["gpu_device_id"] = 0  # CUDA_VISIBLE_DEVICES=3ìœ¼ë¡œ ì„¤ì •í–ˆìœ¼ë¯€ë¡œ 0ë²ˆì´ ì‹¤ì œ GPU 3ë²ˆ
    params["max_bin"] = 255
    params["num_threads"] = 1  # GPU ì‚¬ìš© ì‹œ ìŠ¤ë ˆë“œ ì œí•œ
    params["force_col_wise"] = True  # GPU ìµœì í™”
    print(f"ğŸ”¥ LightGBM forcing GPU #3 usage with device=gpu")
    
    model = lgb.LGBMRegressor(**params)
    
    # ì˜¤ë²„í”¼íŒ… ê°ì§€ë¥¼ ìœ„í•œ ì½œë°± ì„¤ì •
    callbacks = [
        lgb.early_stopping(150, verbose=False),
        lgb.log_evaluation(period=500)  # 500 ì—í­ë§ˆë‹¤ë§Œ ì¶œë ¥
    ]
    
    model.fit(
        X_tr, y_tr,
        eval_set=[(X_val, y_val)],
        eval_metric=lambda y,p: ("SMAPE", smape_np(np.expm1(y), np.expm1(p)), False),
        categorical_feature="auto",  # GPUì—ì„œ ì¹´í…Œê³ ë¦¬ ìë™ ê°ì§€
        callbacks=callbacks,
    )
    preds = model.predict(X_val)
    return smape_np(np.expm1(y_val), np.expm1(preds))

def xgb_objective(trial, X_tr, y_tr, X_val, y_val, use_gpu=False):
    params = {
        "objective": "reg:squarederror",
        "random_state": SEED,
        "learning_rate": trial.suggest_float("lr", 0.01, 0.1, log=True),
        "max_depth": trial.suggest_int("max_depth", 3, 10),  # ì•ˆì •ì ì¸ ë²”ìœ„
        "subsample": trial.suggest_float("subsample", 0.6, 1.0),
        "colsample_bytree": trial.suggest_float("colsample", 0.6, 1.0),
        "min_child_weight": trial.suggest_int("min_child_weight", 1, 20),
        "reg_alpha": trial.suggest_float("ra", 1e-8, 10.0, log=True),
        "reg_lambda": trial.suggest_float("rl", 1e-8, 10.0, log=True),
        "n_estimators": 1000,  # ì•ˆì •ì ì¸ ìˆ˜ëŸ‰
        "verbosity": 0,  # ì™„ì „ ë¬´ìŒ
        "n_jobs": 1,  # GPU ì‚¬ìš© ì‹œ ìŠ¤ë ˆë“œ ì œí•œ
    }
    
    if not use_gpu:
        raise RuntimeError("ğŸš« GPU mode required! Use --gpu flag or remove --gpu to allow CPU")
    
    # GPU ì „ìš© ì„¤ì • - ê°•ì œ GPU #3 ì‚¬ìš©
    params["tree_method"] = "gpu_hist"
    params["gpu_id"] = 0  # CUDA_VISIBLE_DEVICES=3ìœ¼ë¡œ ì„¤ì •í–ˆìœ¼ë¯€ë¡œ 0ë²ˆì´ ì‹¤ì œ GPU 3ë²ˆ
    params["max_bin"] = 256
    params["grow_policy"] = "lossguide"
    params["predictor"] = "gpu_predictor"  # GPU ì˜ˆì¸¡ê¸° ê°•ì œ
    print(f"ğŸ”¥ XGBoost forcing GPU #3 usage with tree_method=gpu_hist")
    
    model = xgb.XGBRegressor(**params)
    model.fit(X_tr, y_tr)  # Optuna objectiveì—ì„œëŠ” early stopping ì œê±°
    preds = model.predict(X_val)
    return smape_np(np.expm1(y_val), np.expm1(preds))

###########################################################
# Training per building
###########################################################

def train_building(df_tr: pd.DataFrame, df_te: pd.DataFrame, feats: list, n_trials: int, use_gpu: bool, lgb_gpu: bool, xgb_gpu: bool):
    # Area for inverse transform
    area_tr = df_tr["ì—°ë©´ì (m2)"].values
    area_te = df_te["ì—°ë©´ì (m2)"].values if not df_te.empty else None
    y_tr_log = df_tr["log_power_pa"].values

    X_full = df_tr[feats]
    scaler = RobustScaler()
    X_scaled = scaler.fit_transform(X_full)
    X_scaled = pd.DataFrame(X_scaled, columns=feats, index=df_tr.index)

    tscv = TimeSeriesSplit(n_splits=3, test_size=24*7)

    oof_pred_lgb = np.zeros(len(df_tr))
    oof_pred_xgb = np.zeros(len(df_tr))
    best_iters_lgb = []
    best_iters_xgb = []
    
    for fold,(tr_idx,val_idx) in enumerate(tscv.split(X_scaled)):
        print(f"    Fold {fold+1}/3 ğŸš€ Starting GPU training...")
        X_tr = X_scaled.iloc[tr_idx]
        y_tr_f = y_tr_log[tr_idx]
        X_val = X_scaled.iloc[val_idx]
        y_val_f = y_tr_log[val_idx]

        # LightGBM ìµœì í™” (GPU ì§‘ì•½ì )
        print(f"      ğŸ”¥ Starting LightGBM GPU optimization...")
        study_lgb = optuna.create_study(
            direction="minimize",
            sampler=optuna.samplers.TPESampler(n_startup_trials=20)  # ë” ë¹ ë¥¸ ìˆ˜ë ´
        )
        study_lgb.optimize(
            lambda tr: lgb_objective(tr, X_tr, y_tr_f, X_val, y_val_f, "auto", True), 
            n_trials=n_trials,  # ë” ë§ì€ trials (XGBì™€ ë™ì‹œ ì‹¤í–‰)
            show_progress_bar=False,
            n_jobs=1  # GPUëŠ” ë‹¨ì¼ ì‘ì—…ì´ ë” íš¨ìœ¨ì 
        )
        print(f"      ğŸ” LGB best SMAPE: {study_lgb.best_value:.3f}%")
        best_lgb_params = study_lgb.best_params
        # GPU ì „ìš© - ë¬´ì¡°ê±´ GPU #3 ì‚¬ìš©
        if not lgb_gpu:
            raise RuntimeError("ğŸš« LightGBM GPU not available! Cannot proceed.")
            
        best_lgb_params.update({
            "objective": "regression_l1",
            "random_state": SEED,
            "learning_rate": best_lgb_params.pop("lr"),
            "num_leaves": best_lgb_params.pop("num_leaves"),
            "subsample": best_lgb_params.pop("subsample"),
            "colsample_bytree": best_lgb_params.pop("colsample"),
            "min_data_in_leaf": best_lgb_params.pop("min_leaf"),
            "reg_alpha": best_lgb_params.pop("ra"),
            "reg_lambda": best_lgb_params.pop("rl"),
            "n_estimators": 8000,  # ë” ë§ì€ estimators
            "verbose": -1,
            "num_threads": 1,  # GPU ì‚¬ìš© ì‹œ ìŠ¤ë ˆë“œ ì œí•œ
            "device": "gpu",
            "gpu_use_dp": True,
            "gpu_platform_id": 0,
            "gpu_device_id": 0,  # CUDA_VISIBLE_DEVICES=3ì´ë¯€ë¡œ 0ë²ˆì´ GPU 3ë²ˆ
            "max_bin": 255,
            "force_col_wise": True  # GPU ìµœì í™”
        })
        
        model_lgb = lgb.LGBMRegressor(**best_lgb_params)
        # GPU ì „ìš© early stopping  
        patience = 300
        callbacks_lgb = [
            lgb.early_stopping(patience, verbose=False),
            lgb.log_evaluation(period=0)  # ë¡œê·¸ ì¶œë ¥ ë¹„í™œì„±í™”
        ]
        
        model_lgb.fit(
            X_tr, y_tr_f, 
            eval_set=[(X_val, y_val_f)],
            categorical_feature="auto",  # GPUì—ì„œ ì¹´í…Œê³ ë¦¬ ìë™ ê°ì§€  
            callbacks=callbacks_lgb
        )
        oof_pred_lgb[val_idx] = model_lgb.predict(X_val)
        best_iters_lgb.append(model_lgb.best_iteration_)

        # XGBoost ìµœì í™” (GPU ì§‘ì•½ì )
        print(f"      ğŸ”¥ Starting XGBoost GPU optimization...")
        study_xgb = optuna.create_study(
            direction="minimize",
            sampler=optuna.samplers.TPESampler(n_startup_trials=20)  # ë” ë¹ ë¥¸ ìˆ˜ë ´
        )
        study_xgb.optimize(
            lambda tr: xgb_objective(tr, X_tr, y_tr_f, X_val, y_val_f, True),
            n_trials=n_trials,  # ë” ë§ì€ trials
            show_progress_bar=False,
            n_jobs=1  # GPUëŠ” ë‹¨ì¼ ì‘ì—…ì´ ë” íš¨ìœ¨ì 
        )
        print(f"      ğŸ” XGB best SMAPE: {study_xgb.best_value:.3f}%")
        best_xgb_params = study_xgb.best_params
        # GPU ì „ìš© - ë¬´ì¡°ê±´ GPU #3 ì‚¬ìš©
        if not xgb_gpu:
            raise RuntimeError("ğŸš« XGBoost GPU not available! Cannot proceed.")
            
        best_xgb_params.update({
            "objective": "reg:squarederror",
            "random_state": SEED,
            "learning_rate": best_xgb_params.pop("lr"),
            "max_depth": best_xgb_params.pop("max_depth"),
            "subsample": best_xgb_params.pop("subsample"),
            "colsample_bytree": best_xgb_params.pop("colsample"),
            "min_child_weight": best_xgb_params.pop("min_child_weight"),
            "reg_alpha": best_xgb_params.pop("ra"),
            "reg_lambda": best_xgb_params.pop("rl"),
            "n_estimators": 8000,  # ë” ë§ì€ estimators
            "verbosity": 0,
            "n_jobs": 1,  # GPU ì‚¬ìš© ì‹œ ìŠ¤ë ˆë“œ ì œí•œ
            "tree_method": "gpu_hist",
            "gpu_id": 0,  # CUDA_VISIBLE_DEVICES=3ì´ë¯€ë¡œ 0ë²ˆì´ GPU 3ë²ˆ
            "predictor": "gpu_predictor",  # GPU ì˜ˆì¸¡ê¸° ê°•ì œ
            "max_bin": 256,
            "grow_policy": "lossguide"
        })
        
        model_xgb = xgb.XGBRegressor(**best_xgb_params)
        # GPU ì „ìš© early stopping (ì½œë°± ë°©ì‹)
        xgb_patience = 300
        model_xgb.fit(
            X_tr, y_tr_f,
            eval_set=[(X_val, y_val_f)],
            callbacks=[xgb.callback.EarlyStopping(rounds=xgb_patience, save_best=True)],
            verbose=0  # ì™„ì „ ë¬´ìŒ
        )
        oof_pred_xgb[val_idx] = model_xgb.predict(X_val)
        best_iters_xgb.append(model_xgb.best_iteration)

    # ì•™ìƒë¸” (LightGBM 60% + XGBoost 40%)
    oof_pred_ensemble = 0.6 * oof_pred_lgb + 0.4 * oof_pred_xgb
    sm = smape_np(df_tr["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].values, np.expm1(oof_pred_ensemble)*area_tr)
    
    # ì˜¤ë²„í”¼íŒ… ì²´í¬: ê°œë³„ ëª¨ë¸ê³¼ ì•™ìƒë¸” ì„±ëŠ¥ ë¹„êµ
    sm_lgb = smape_np(df_tr["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].values, np.expm1(oof_pred_lgb)*area_tr)
    sm_xgb = smape_np(df_tr["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].values, np.expm1(oof_pred_xgb)*area_tr)
    
    print(f"    ğŸ“Š LGB: {sm_lgb:.3f}% | XGB: {sm_xgb:.3f}% | Ensemble: {sm:.3f}%")
    
    # ì˜¤ë²„í”¼íŒ… ê²½ê³ 
    if sm > min(sm_lgb, sm_xgb) + 0.5:
        print(f"    âš ï¸  ì•™ìƒë¸” ì„±ëŠ¥ ì €í•˜ ê°ì§€ (ê°œë³„ ëª¨ë¸ë³´ë‹¤ {sm - min(sm_lgb, sm_xgb):.2f}%p ë†’ìŒ)")
    
    if np.mean(best_iters_lgb) < 200 or np.mean(best_iters_xgb) < 200:
        print(f"    âš ï¸  ì¡°ê¸° ìˆ˜ë ´ ê°ì§€ (LGB: {np.mean(best_iters_lgb):.0f}, XGB: {np.mean(best_iters_xgb):.0f})")
    elif np.mean(best_iters_lgb) > 2500 or np.mean(best_iters_xgb) > 2500:
        print(f"    âš ï¸  ì˜¤ë²„í”¼íŒ… ìœ„í—˜ (LGB: {np.mean(best_iters_lgb):.0f}, XGB: {np.mean(best_iters_xgb):.0f})")

    # train final models on all data with optimal iterations
    # Use average best iterations from cross-validation with some buffer
    avg_lgb_iter = int(np.mean(best_iters_lgb) * 1.1) if best_iters_lgb else 3000
    avg_xgb_iter = int(np.mean(best_iters_xgb) * 1.1) if best_iters_xgb else 3000
    
    best_lgb_params_final = best_lgb_params.copy()
    best_lgb_params_final['n_estimators'] = avg_lgb_iter
    
    best_xgb_params_final = best_xgb_params.copy()
    best_xgb_params_final['n_estimators'] = avg_xgb_iter
    
    print(f"    ğŸ”¥ Final GPU training - LGB iters: {avg_lgb_iter}, XGB iters: {avg_xgb_iter}")
    
    print(f"    ğŸ”¥ Training final LightGBM on GPU #3...")
    final_lgb = lgb.LGBMRegressor(**best_lgb_params_final)
    final_lgb.fit(X_scaled, y_tr_log, categorical_feature="auto")
    
    print(f"    ğŸ”¥ Training final XGBoost on GPU #3...")
    final_xgb = xgb.XGBRegressor(**best_xgb_params_final)
    final_xgb.fit(X_scaled, y_tr_log)

    # prediction
    preds_df = None
    if not df_te.empty:
        X_te = scaler.transform(df_te[feats])
        pred_lgb = final_lgb.predict(X_te)
        pred_xgb = final_xgb.predict(X_te)
        pred_ensemble = 0.6 * pred_lgb + 0.4 * pred_xgb
        pred_kwh = np.expm1(pred_ensemble) * area_te
        preds_df = pd.DataFrame({
            "num_date_time": df_te["num_date_time"],
            "answer": pred_kwh.clip(min=0)
        })
    return sm, preds_df

###########################################################
# Main Pipeline
###########################################################

def run_pipeline(train_path: Path, test_path: Path, info_path: Path, n_trials: int, use_gpu: bool):
    print("ğŸ“¥ Loading data ... (CPU preprocessing)")
    train_df = pd.read_csv(train_path, parse_dates=["ì¼ì‹œ"])
    test_df = pd.read_csv(test_path, parse_dates=["ì¼ì‹œ"])
    info_df = pd.read_csv(info_path)

    # GPU ì§€ì› í™•ì¸
    lgb_gpu, xgb_gpu = False, False
    if use_gpu:
        print("\nğŸš€ Checking GPU support...")
        lgb_gpu, xgb_gpu = check_gpu_support()

    # Missing indicators BEFORE replacement
    miss_cols = ["íƒœì–‘ê´‘ìš©ëŸ‰(kW)", "ESSì €ì¥ìš©ëŸ‰(kWh)", "PCSìš©ëŸ‰(kW)"]
    for c in miss_cols:
        info_df[f"{c}_missing"] = (info_df[c] == "-").astype(int)

    num_cols = ["ì—°ë©´ì (m2)", "ëƒ‰ë°©ë©´ì (m2)", "íƒœì–‘ê´‘ìš©ëŸ‰(kW)", "ESSì €ì¥ìš©ëŸ‰(kWh)", "PCSìš©ëŸ‰(kW)"]
    info_df[num_cols] = info_df[num_cols].replace("-", 0).astype(float)

    train = train_df.merge(info_df, on="ê±´ë¬¼ë²ˆí˜¸", how="left")
    test = test_df.merge(info_df, on="ê±´ë¬¼ë²ˆí˜¸", how="left")
    test["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"] = np.nan

    all_df = pd.concat([train, test], ignore_index=True)

    # Feature engineering
    print("ğŸ”§ Feature engineering ... (CPU preprocessing)")
    all_df = add_time_features(all_df)
    all_df = add_weather_features(all_df)

    # Target scaling
    all_df["power_per_area"] = all_df["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"] / (all_df["ì—°ë©´ì (m2)"].replace(0, np.nan))
    all_df["log_power_pa"] = np.log1p(all_df["power_per_area"].clip(lower=0))

    # Feature list
    feats = [
        "ê±´ë¬¼ë²ˆí˜¸","ê¸°ì˜¨(Â°C)","í’ì†(m/s)","ìŠµë„(%)","ì—°ë©´ì (m2)","ëƒ‰ë°©ë©´ì (m2)",
        "íƒœì–‘ê´‘ìš©ëŸ‰(kW)","ESSì €ì¥ìš©ëŸ‰(kWh)","PCSìš©ëŸ‰(kW)",
        "dew_point","heat_index","THI","THI_diff_24h","temp_diff_1h","temp_diff_6h",
        "month","day","hour","weekday","is_weekend","is_holiday",
        "hour_sin","hour_cos","month_sin","month_cos","weekday_sin","weekday_cos"
    ] + [f"{c}_missing" for c in miss_cols]

    df_train = all_df[~all_df["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].isna()].copy()
    df_test = all_df[all_df["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].isna()].copy()

    # num_date_time ì»¬ëŸ¼ ìƒì„± (submission.csvë¥¼ ìœ„í•´ í•„ìš”)
    print("ğŸ”§ Creating num_date_time column...")
    df_test['num_date_time'] = df_test['ê±´ë¬¼ë²ˆí˜¸'].astype(str) + '_' + df_test['ì¼ì‹œ'].dt.strftime('%Y%m%d %H')

    # train per building
    print("ğŸ—ï¸ Starting building-wise training ... (switching to GPU)")
    sub_parts = []
    scores = []
    for bid in df_train["ê±´ë¬¼ë²ˆí˜¸"].unique():
        print(f"\nğŸ¢ Building {bid}")
        tr_b = df_train[df_train["ê±´ë¬¼ë²ˆí˜¸"] == bid].copy()
        te_b = df_test[df_test["ê±´ë¬¼ë²ˆí˜¸"] == bid].copy()
        if len(tr_b) < 200:
            print(f"  âš ï¸ Skipping Building {bid} - insufficient data ({len(tr_b)} < 200)")
            continue
        sm, preds = train_building(tr_b, te_b, feats, n_trials, use_gpu, lgb_gpu, xgb_gpu)
        scores.append(sm)
        if preds is not None:
            sub_parts.append(preds)
            print(f"  âœ… Building {bid} predictions added ({len(preds)} rows)")

    print(f"\nğŸ“ˆ Average OOF SMAPE: {np.mean(scores):.3f}%")
    
    if sub_parts:
        print(f"ğŸ”— Concatenating {len(sub_parts)} building predictions...")
        submission = pd.concat(sub_parts, ignore_index=True)
        print(f"   Combined predictions shape: {submission.shape}")
        
        # align with sample_submission if exists
        sample_path = test_path.parent / "sample_submission.csv"
        if sample_path.exists():
            print("ğŸ“‹ Aligning with sample_submission.csv...")
            sample = pd.read_csv(sample_path).drop(columns=["answer"], errors="ignore")
            submission = sample.merge(submission, on="num_date_time", how="left")
            print(f"   Final submission shape: {submission.shape}")
        
        submission.to_csv("submission.csv", index=False)
        print("âœ… submission.csv saved.")
    else:
        print("âŒ No predictions generated! Check building data or training process.")
        # ê¸°ë³¸ ì œì¶œ íŒŒì¼ ìƒì„±
        sample_path = test_path.parent / "sample_submission.csv"
        if sample_path.exists():
            sample = pd.read_csv(sample_path)
            sample.to_csv("submission.csv", index=False)
            print("ğŸ“ Default submission.csv created from sample.")

###########################################################
if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--train", type=Path, default=Path("data/train.csv"))
    ap.add_argument("--test", type=Path, default=Path("data/test.csv"))
    ap.add_argument("--info", type=Path, default=Path("data/building_info.csv"))
    ap.add_argument("--n-trials", type=int, default=20)
    ap.add_argument("--gpu", action="store_true", help="GPU ê°€ì† ì‚¬ìš©")
    args = ap.parse_args()
    run_pipeline(args.train, args.test, args.info, args.n_trials, args.gpu) 