import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import holidays
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
import xgboost as xgb
from xgboost import XGBRegressor
import joblib
import os
import json
from datetime import datetime

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.size'] = 10

print("="*60)
print("ğŸš€ XGBoost Model Training for Power Consumption Prediction")
print("="*60)

def smape(y_true, y_pred):
    """SMAPE ê³„ì‚° í•¨ìˆ˜"""
    epsilon = 1e-10
    numerator = 2 * np.abs(y_pred - y_true)
    denominator = np.abs(y_true) + np.abs(y_pred) + epsilon
    return np.mean(numerator / denominator) * 100

def create_features(df):
    """í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ìˆ˜í–‰"""
    print("ğŸ”§ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ìˆ˜í–‰ ì¤‘...")
    
    df = df.sort_values(by=['ê±´ë¬¼ë²ˆí˜¸', 'ì¼ì‹œ']).reset_index(drop=True)
    
    # 1. ì‹œê°„ ê´€ë ¨ í”¼ì²˜
    df['month'] = df['ì¼ì‹œ'].dt.month
    df['day'] = df['ì¼ì‹œ'].dt.day
    df['hour'] = df['ì¼ì‹œ'].dt.hour
    df['weekday'] = df['ì¼ì‹œ'].dt.weekday
    df['is_weekend'] = (df['weekday'] >= 5).astype(int)
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    
    # 2. ê³µíœ´ì¼ í”¼ì²˜ ì¶”ê°€
    kr_holidays = holidays.KR()
    df['is_holiday'] = df['ì¼ì‹œ'].dt.date.apply(lambda x: 1 if x in kr_holidays else 0).astype(int)
    
    # 3. ë‚ ì”¨ ê´€ë ¨ í”¼ì²˜ (THI - Temperature Humidity Index)
    df['THI'] = 9/5 * df['ê¸°ì˜¨(Â°C)'] - 0.55 * (1 - df['ìŠµë„(%)']/100) * (9/5 * df['ê¸°ì˜¨(Â°C)'] - 26) + 32
    
    # 4. ìƒí˜¸ì‘ìš© ë° ì´ë™í†µê³„ í”¼ì²˜
    df['temp_x_hour'] = df['ê¸°ì˜¨(Â°C)'] * df['hour']
    df['temp_rolling_mean_6'] = df.groupby('ê±´ë¬¼ë²ˆí˜¸')['ê¸°ì˜¨(Â°C)'].transform(lambda x: x.rolling(window=6, min_periods=1).mean())
    df['temp_rolling_std_6'] = df.groupby('ê±´ë¬¼ë²ˆí˜¸')['ê¸°ì˜¨(Â°C)'].transform(lambda x: x.rolling(window=6, min_periods=1).std()).fillna(0)

    # 5. ì‹œì°¨ ë³€ìˆ˜ (Data Leakage ë°©ì§€)
    lags = [24, 48, 168]
    for lag in lags:
        df[f'power_lag_{lag}'] = df.groupby('ê±´ë¬¼ë²ˆí˜¸')['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].transform(lambda x: x.shift(lag))
        df[f'temp_lag_{lag}'] = df.groupby('ê±´ë¬¼ë²ˆí˜¸')['ê¸°ì˜¨(Â°C)'].transform(lambda x: x.shift(lag))
    
    # 6. ê³„ì ˆì„± í”¼ì²˜ ì¶”ê°€
    df['season'] = df['month'].map({12: 0, 1: 0, 2: 0,  # ê²¨ìš¸
                                    3: 1, 4: 1, 5: 1,    # ë´„
                                    6: 2, 7: 2, 8: 2,    # ì—¬ë¦„
                                    9: 3, 10: 3, 11: 3}) # ê°€ì„
    
    # 7. ë” ë§ì€ ì‹œê°„ í”¼ì²˜
    df['dayofyear'] = df['ì¼ì‹œ'].dt.dayofyear
    df['week_of_year'] = df['ì¼ì‹œ'].dt.isocalendar().week
    df['is_month_start'] = df['ì¼ì‹œ'].dt.is_month_start.astype(int)
    df['is_month_end'] = df['ì¼ì‹œ'].dt.is_month_end.astype(int)
    
    print(f"âœ… í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ - ì´ {len(df.columns)}ê°œ ì»¬ëŸ¼")
    return df

def prepare_data():
    """ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬"""
    print("\nğŸ“Š ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ì‹œì‘...")
    
    # ë°ì´í„° ë¡œë“œ
    train_df = pd.read_csv('data/train.csv', parse_dates=['ì¼ì‹œ'])
    test_df = pd.read_csv('data/test.csv', parse_dates=['ì¼ì‹œ'])
    building_info_df = pd.read_csv('data/building_info.csv')
    
    print(f"âœ… í›ˆë ¨ ë°ì´í„°: {train_df.shape}")
    print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_df.shape}")
    print(f"âœ… ê±´ë¬¼ ì •ë³´: {building_info_df.shape}")

    # ê±´ë¬¼ ì •ë³´ ìˆ˜ì¹˜í˜• ë³€í™˜
    numeric_cols = ['ì—°ë©´ì (m2)', 'ëƒ‰ë°©ë©´ì (m2)', 'íƒœì–‘ê´‘ìš©ëŸ‰(kW)', 'ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)']
    for col in numeric_cols:
        building_info_df[col] = building_info_df[col].replace('-', '0').astype(float)

    # ê±´ë¬¼ ì •ë³´ ë³‘í•©
    train_df = pd.merge(train_df, building_info_df, on='ê±´ë¬¼ë²ˆí˜¸', how='left')
    test_df = pd.merge(test_df, building_info_df, on='ê±´ë¬¼ë²ˆí˜¸', how='left')
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ë”ë¯¸ íƒ€ê²Ÿ ë³€ìˆ˜ ì¶”ê°€
    test_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'] = np.nan
    
    # ì „ì²´ ë°ì´í„° ê²°í•©í•˜ì—¬ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    combined_df = pd.concat([train_df, test_df], ignore_index=True)
    combined_df = create_features(combined_df)
    
    # ì¹´í…Œê³ ë¦¬ì»¬ ë³€ìˆ˜ ì²˜ë¦¬ - XGBoostë¥¼ ìœ„í•´ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
    from sklearn.preprocessing import LabelEncoder
    
    # ê±´ë¬¼ë²ˆí˜¸ë¥¼ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
    le_building = LabelEncoder()
    combined_df['ê±´ë¬¼ë²ˆí˜¸'] = le_building.fit_transform(combined_df['ê±´ë¬¼ë²ˆí˜¸'])
    
    # ê±´ë¬¼ìœ í˜•ì€ ë¬¸ìì—´ë¡œ ìœ ì§€ (ë‚˜ì¤‘ì— í•„í„°ë§ìš©ìœ¼ë¡œ ì‚¬ìš©)
    combined_df['ê±´ë¬¼ìœ í˜•'] = combined_df['ê±´ë¬¼ìœ í˜•'].astype(str)
    
    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
    train_processed_df = combined_df[~combined_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].isna()].copy()
    test_processed_df = combined_df[combined_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].isna()].copy()
    
    print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ - í›ˆë ¨: {train_processed_df.shape}, í…ŒìŠ¤íŠ¸: {test_processed_df.shape}")
    
    return train_processed_df, test_processed_df

def get_feature_list():
    """ì‚¬ìš©í•  í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    features = [
        'ê±´ë¬¼ë²ˆí˜¸', 'ê¸°ì˜¨(Â°C)', 'í’ì†(m/s)', 'ìŠµë„(%)',
        'ì—°ë©´ì (m2)', 'ëƒ‰ë°©ë©´ì (m2)', 'íƒœì–‘ê´‘ìš©ëŸ‰(kW)', 'ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)',
        'month', 'day', 'hour', 'weekday', 'is_weekend', 'is_holiday',
        'hour_sin', 'hour_cos', 'THI', 'temp_x_hour', 
        'temp_rolling_mean_6', 'temp_rolling_std_6',
        'power_lag_24', 'temp_lag_24', 'power_lag_48', 'temp_lag_48', 'power_lag_168', 'temp_lag_168',
        'season', 'dayofyear', 'week_of_year', 'is_month_start', 'is_month_end'
    ]
    return features

def train_building_type_models(train_df, test_df):
    """ê±´ë¬¼ ìœ í˜•ë³„ XGBoost ëª¨ë¸ í›ˆë ¨"""
    print("\nğŸ—ï¸ ê±´ë¬¼ ìœ í˜•ë³„ XGBoost ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    
    features = get_feature_list()
    
    building_types = train_df['ê±´ë¬¼ìœ í˜•'].unique()
    total_predictions = []
    total_smape_score = 0
    model_results = {}
    
    # ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±
    os.makedirs('result', exist_ok=True)
    
    for b_type in building_types:
        print(f"\n--- {b_type} ìœ í˜• ëª¨ë¸ í›ˆë ¨ ---")
        
        # ê±´ë¬¼ ìœ í˜•ë³„ ë°ì´í„° í•„í„°ë§
        type_train_df = train_df[train_df['ê±´ë¬¼ìœ í˜•'] == b_type].copy()
        
        # ì‹œê³„ì—´ ë¶„í•  (ê²€ì¦ìš©)
        split_date = pd.to_datetime('2024-08-18 00:00:00')
        train_val_df = type_train_df[type_train_df['ì¼ì‹œ'] < split_date]
        valid_df = type_train_df[type_train_df['ì¼ì‹œ'] >= split_date]

        X_train_val = train_val_df[features]
        y_train_val = train_val_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
        X_valid = valid_df[features]
        y_valid = valid_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']

        # XGBoost íŒŒë¼ë¯¸í„° ì„¤ì •
        xgb_params = {
            'objective': 'reg:squarederror',
            'eval_metric': 'mae',
            'n_estimators': 2000,
            'max_depth': 8,
            'learning_rate': 0.05,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'colsample_bylevel': 0.8,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1,
            'min_child_weight': 3,
            'gamma': 0.1,
            'random_state': 42,
            'n_jobs': -1,
            'tree_method': 'hist',
            'verbosity': 0
        }
        
        # ëª¨ë¸ í›ˆë ¨ (ê²€ì¦ìš©)
        xgb_params_with_early_stop = xgb_params.copy()
        xgb_params_with_early_stop['early_stopping_rounds'] = 100
        
        xgb_model = XGBRegressor(**xgb_params_with_early_stop)
        xgb_model.fit(
            X_train_val, y_train_val,
            eval_set=[(X_valid, y_valid)],
            verbose=False
        )
        
        # ê²€ì¦ ì„±ëŠ¥ í‰ê°€
        best_iter = xgb_model.get_booster().best_iteration
        valid_preds = xgb_model.predict(X_valid)
        valid_preds[valid_preds < 0] = 0
        type_smape = smape(y_valid.values, valid_preds)
        total_smape_score += type_smape
        
        print(f"âœ… {b_type} ê²€ì¦ SMAPE: {type_smape:.4f} (ìµœì  ë°˜ë³µ: {best_iter})")

        # ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í›ˆë ¨
        X_train_full = type_train_df[features]
        y_train_full = type_train_df['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
        
        # ìµœì  ë°˜ë³µìˆ˜ë¡œ ì¬í›ˆë ¨
        final_xgb_params = xgb_params.copy()
        final_xgb_params['n_estimators'] = best_iter + 50  # ì—¬ìœ ë¶„ ì¶”ê°€
        
        final_model = XGBRegressor(**final_xgb_params)
        final_model.fit(X_train_full, y_train_full)
        
        # ëª¨ë¸ ì €ì¥
        model_path = f'result/xgboost_model_{b_type}.pkl'
        joblib.dump(final_model, model_path)
        
        # í•´ë‹¹ ê±´ë¬¼ ìœ í˜•ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
        type_test_df = test_df[test_df['ê±´ë¬¼ìœ í˜•'] == b_type]
        
        if not type_test_df.empty:
            X_test = type_test_df[features]
            preds = final_model.predict(X_test)
            preds[preds < 0] = 0  # ìŒìˆ˜ ì˜ˆì¸¡ê°’ ì œê±°
            
            temp_submission = pd.DataFrame({
                'num_date_time': type_test_df['num_date_time'], 
                'answer': preds
            })
            total_predictions.append(temp_submission)
            
            print(f"âœ… {b_type} ì˜ˆì¸¡ ì™„ë£Œ: {len(preds)}ê°œ ìƒ˜í”Œ")
        
        # ëª¨ë¸ ê²°ê³¼ ì €ì¥
        model_results[b_type] = {
            'smape': type_smape,
            'best_iteration': best_iter,
            'train_samples': len(X_train_full),
            'test_samples': len(type_test_df) if not type_test_df.empty else 0
        }

    print(f"\nğŸ“Š ì „ì²´ í‰ê·  ê²€ì¦ SMAPE: {total_smape_score / len(building_types):.4f}")
    
    return total_predictions, model_results

def create_submission_file(predictions, model_results):
    """ì œì¶œ íŒŒì¼ ìƒì„±"""
    print("\nğŸ“„ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    
    # ëª¨ë“  ì˜ˆì¸¡ ê²°ê³¼ ê²°í•©
    final_submission = pd.concat(predictions, ignore_index=True)
    
    # sample_submissionê³¼ í˜•ì‹ ë§ì¶”ê¸°
    sample_submission = pd.read_csv('data/sample_submission.csv')
    sample_submission = sample_submission.drop(columns=['answer'])
    final_submission = pd.merge(sample_submission, final_submission, on='num_date_time', how='left')
    
    # ëˆ„ë½ëœ ê°’ í™•ì¸ ë° ì²˜ë¦¬
    if final_submission['answer'].isna().sum() > 0:
        print(f"âš ï¸ ëˆ„ë½ëœ ì˜ˆì¸¡ê°’ {final_submission['answer'].isna().sum()}ê°œë¥¼ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´")
        final_submission['answer'].fillna(final_submission['answer'].mean(), inplace=True)
    
    # ì œì¶œ íŒŒì¼ ì €ì¥
    submission_path = 'result/submission.csv'
    final_submission.to_csv(submission_path, index=False)
    
    print(f"âœ… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {submission_path}")
    print(f"âœ… ì œì¶œ íŒŒì¼ í¬ê¸°: {final_submission.shape}")
    print(f"âœ… ì˜ˆì¸¡ê°’ ë²”ìœ„: {final_submission['answer'].min():.2f} ~ {final_submission['answer'].max():.2f}")
    
    return final_submission

def create_analysis_report(model_results, submission_df):
    """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
    print("\nğŸ“Š ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    
    # ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½
    report = {
        'model_summary': {
            'total_building_types': len(model_results),
            'average_smape': np.mean([result['smape'] for result in model_results.values()]),
            'model_details': model_results
        },
        'prediction_summary': {
            'total_predictions': len(submission_df),
            'prediction_stats': {
                'min': float(submission_df['answer'].min()),
                'max': float(submission_df['answer'].max()),
                'mean': float(submission_df['answer'].mean()),
                'std': float(submission_df['answer'].std())
            }
        },
        'training_info': {
            'model_type': 'XGBoost',
            'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'features_used': get_feature_list()
        }
    }
    
    # JSON ë¦¬í¬íŠ¸ ì €ì¥
    report_path = 'result/analysis_report.json'
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=4, ensure_ascii=False)
    
    print(f"âœ… ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
    
    # ì‹œê°í™” ìƒì„±
    create_visualizations(model_results, submission_df)
    
    return report

def create_visualizations(model_results, submission_df):
    """ì‹œê°í™” ìƒì„±"""
    print("ğŸ¨ ì‹œê°í™” ìƒì„± ì¤‘...")
    
    plt.figure(figsize=(15, 10))
    
    # 1. ê±´ë¬¼ ìœ í˜•ë³„ SMAPE ì„±ëŠ¥
    plt.subplot(2, 3, 1)
    building_types = list(model_results.keys())
    smape_scores = [model_results[bt]['smape'] for bt in building_types]
    
    plt.bar(range(len(building_types)), smape_scores, color='skyblue', alpha=0.7)
    plt.xlabel('Building Type')
    plt.ylabel('SMAPE')
    plt.title('SMAPE by Building Type')
    plt.xticks(range(len(building_types)), [bt[:10] for bt in building_types], rotation=45)
    plt.grid(True, alpha=0.3)
    
    # 2. ì˜ˆì¸¡ê°’ ë¶„í¬
    plt.subplot(2, 3, 2)
    plt.hist(submission_df['answer'], bins=50, alpha=0.7, edgecolor='black')
    plt.xlabel('Predicted Power Consumption (kWh)')
    plt.ylabel('Frequency')
    plt.title('Distribution of Predictions')
    plt.grid(True, alpha=0.3)
    
    # 3. ê±´ë¬¼ ìœ í˜•ë³„ í›ˆë ¨ ìƒ˜í”Œ ìˆ˜
    plt.subplot(2, 3, 3)
    train_samples = [model_results[bt]['train_samples'] for bt in building_types]
    plt.bar(range(len(building_types)), train_samples, color='lightgreen', alpha=0.7)
    plt.xlabel('Building Type')
    plt.ylabel('Training Samples')
    plt.title('Training Samples by Building Type')
    plt.xticks(range(len(building_types)), [bt[:10] for bt in building_types], rotation=45)
    plt.grid(True, alpha=0.3)
    
    # 4. ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½
    plt.subplot(2, 3, 4)
    avg_smape = np.mean(smape_scores)
    plt.text(0.1, 0.8, f'Average SMAPE: {avg_smape:.4f}', fontsize=14, transform=plt.gca().transAxes)
    plt.text(0.1, 0.6, f'Best SMAPE: {min(smape_scores):.4f}', fontsize=12, transform=plt.gca().transAxes)
    plt.text(0.1, 0.4, f'Worst SMAPE: {max(smape_scores):.4f}', fontsize=12, transform=plt.gca().transAxes)
    plt.text(0.1, 0.2, f'Total Models: {len(building_types)}', fontsize=12, transform=plt.gca().transAxes)
    plt.title('Model Performance Summary')
    plt.axis('off')
    
    # 5. ì˜ˆì¸¡ê°’ í†µê³„
    plt.subplot(2, 3, 5)
    stats = submission_df['answer'].describe()
    y_pos = np.arange(len(stats))
    plt.barh(y_pos, stats.values, color='coral', alpha=0.7)
    plt.yticks(y_pos, [f'{stat}: {val:.2f}' for stat, val in zip(stats.index, stats.values)])
    plt.xlabel('Value')
    plt.title('Prediction Statistics')
    plt.grid(True, alpha=0.3)
    
    # 6. ê±´ë¬¼ ìœ í˜•ë³„ ì˜ˆì¸¡ ê°œìˆ˜
    plt.subplot(2, 3, 6)
    test_samples = [model_results[bt]['test_samples'] for bt in building_types]
    plt.pie(test_samples, labels=[bt[:10] for bt in building_types], autopct='%1.1f%%', startangle=90)
    plt.title('Test Samples Distribution')
    
    plt.tight_layout()
    
    # ì‹œê°í™” ì €ì¥
    viz_path = 'result/model_analysis.png'
    plt.savefig(viz_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… ì‹œê°í™” ì €ì¥: {viz_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        print("ğŸƒâ€â™‚ï¸ XGBoost ì „ë ¥ì†Œë¹„ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ ì‹œì‘!")
        
        # 1. ë°ì´í„° ì¤€ë¹„
        train_df, test_df = prepare_data()
        
        # 2. ê±´ë¬¼ ìœ í˜•ë³„ ëª¨ë¸ í›ˆë ¨
        predictions, model_results = train_building_type_models(train_df, test_df)
        
        # 3. ì œì¶œ íŒŒì¼ ìƒì„±
        submission_df = create_submission_file(predictions, model_results)
        
        # 4. ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        report = create_analysis_report(model_results, submission_df)
        
        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ‰ XGBoost ëª¨ë¸ë§ ì™„ë£Œ!")
        print("="*60)
        print(f"ğŸ“Š ê²°ê³¼ ìš”ì•½:")
        print(f"   â€¢ ê±´ë¬¼ ìœ í˜• ìˆ˜: {len(model_results)}")
        print(f"   â€¢ í‰ê·  SMAPE: {report['model_summary']['average_smape']:.4f}")
        print(f"   â€¢ ì´ ì˜ˆì¸¡ ìƒ˜í”Œ: {len(submission_df)}")
        print(f"")
        print(f"ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
        print(f"   â€¢ result/submission.csv (ì œì¶œ íŒŒì¼)")
        print(f"   â€¢ result/analysis_report.json (ë¶„ì„ ë¦¬í¬íŠ¸)")
        print(f"   â€¢ result/model_analysis.png (ì‹œê°í™”)")
        print(f"   â€¢ result/xgboost_model_*.pkl (ê±´ë¬¼ë³„ ëª¨ë¸)")
        print(f"")
        print("ğŸš€ submission.csv íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("="*60)
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        raise

if __name__ == "__main__":
    main() 