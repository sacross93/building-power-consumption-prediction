import argparse
from pathlib import Path
import os
import warnings

import numpy as np
import pandas as pd

warnings.filterwarnings("ignore")

############################################################
# Helper: Hampel filter for outlier smoothing
############################################################

def hampel_filter(series: pd.Series, window_size: int = 24, n_sigmas: float = 3.0) -> pd.Series:
    """ê°„ë‹¨í•œ Hampel í•„í„° êµ¬í˜„ (window_size ì‹œê°„ ì°½ ê¸°ì¤€)"""
    rolling_median = series.rolling(window=window_size, center=True).median()
    diff = np.abs(series - rolling_median)
    mad = diff.rolling(window=window_size, center=True).median()
    threshold = n_sigmas * 1.4826 * mad  # 1.4826: MAD -> std ê·¼ì‚¬
    outlier_idx = diff > threshold
    series_clean = series.copy()
    series_clean[outlier_idx] = rolling_median[outlier_idx]
    return series_clean

############################################################
# Feature Engineering (ì‹œê°„ & ë‚ ì”¨) â€“ test5.py ì—ì„œ ì‚¬ìš©í•œ í•¨ìˆ˜ ì¼ë¶€ ì¬í™œìš©
############################################################

KR_HOLIDAYS = None  # holidays íŒ¨í‚¤ì§€ ì‚¬ìš©ì€ ì§€ì—° import(ì†ë„)


def add_time_features(df: pd.DataFrame) -> pd.DataFrame:
    dt = df["ì¼ì‹œ"]
    df["month"] = dt.dt.month
    df["day"] = dt.dt.day
    df["hour"] = dt.dt.hour
    df["weekday"] = dt.dt.weekday
    df["is_weekend"] = (df["weekday"] >= 5).astype(int)
    global KR_HOLIDAYS
    if KR_HOLIDAYS is None:
        import holidays
        KR_HOLIDAYS = holidays.KR()
    df["is_holiday"] = dt.dt.date.map(lambda d: int(d in KR_HOLIDAYS))
    # Fourier ë³€í™˜
    df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24)
    df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24)
    df["month_sin"] = np.sin(2 * np.pi * df["month"] / 12)
    df["month_cos"] = np.cos(2 * np.pi * df["month"] / 12)
    df["weekday_sin"] = np.sin(2 * np.pi * df["weekday"] / 7)
    df["weekday_cos"] = np.cos(2 * np.pi * df["weekday"] / 7)
    # ì¶”ì„¸ìš©
    df["day_of_year"] = dt.dt.dayofyear
    df["week_of_year"] = dt.dt.isocalendar().week.astype(int)
    df["time_idx"] = (dt - dt.min()).dt.days
    return df


def add_weather_features(df: pd.DataFrame) -> pd.DataFrame:
    # ê°€ì •: ê¸°ì˜¨(Â°C), ìŠµë„(%), í’ì†(m/s) ì»¬ëŸ¼ì´ ì¡´ì¬
    df["THI"] = 9 / 5 * df["ê¸°ì˜¨(Â°C)"] - 0.55 * (1 - df["ìŠµë„(%)"] / 100) * (9 / 5 * df["ê¸°ì˜¨(Â°C)"] - 26) + 32
    df["dew_point"] = df["ê¸°ì˜¨(Â°C)"] - (100 - df["ìŠµë„(%)"]) / 5
    df["heat_index"] = 0.5 * (df["ê¸°ì˜¨(Â°C)"] + 61.0 + (df["ê¸°ì˜¨(Â°C)"] - 68.0) * 1.2 + df["ìŠµë„(%)"] * 0.094)
    # Degree Days
    df["HDD"] = (18 - df["ê¸°ì˜¨(Â°C)"]).clip(lower=0)
    df["CDD"] = (df["ê¸°ì˜¨(Â°C)"] - 22).clip(lower=0)
    # ì˜¨ë„ êµ¬ê°„ (Bin)
    bins = [-50, 10, 15, 20, 25, 30, 60]
    labels = ["temp_bin_1", "temp_bin_2", "temp_bin_3", "temp_bin_4", "temp_bin_5", "temp_bin_6"]
    df["temp_bin"] = pd.cut(df["ê¸°ì˜¨(Â°C)"], bins=bins, labels=labels)
    return df

############################################################
# Lag & Rolling ìƒì„±ê¸°
############################################################

def create_lag_rolling(df: pd.DataFrame, group_cols: list, target_cols: list) -> pd.DataFrame:
    """ì£¼ì–´ì§„ íƒ€ê²Ÿ ì»¬ëŸ¼ì— ëŒ€í•´ ë™ê³¼ ë¡¤ë§ í”¼ì²˜ë¥¼ ìƒì„±í•œë‹¤."""
    for col in target_cols:
        for lag in [1, 2, 3, 24, 48, 168]:
            df[f"{col}_lag_{lag}"] = df.groupby(group_cols)[col].shift(lag)
        # rolling 6/24 window mean & std (ë‹¨ê¸°, ì¼ê°„)
        for win in [6, 24]:
            df[f"{col}_roll_mean_{win}"] = (
                df.groupby(group_cols)[col].rolling(window=win).mean().reset_index(level=0, drop=True)
            )
            df[f"{col}_roll_std_{win}"] = (
                df.groupby(group_cols)[col].rolling(window=win).std().reset_index(level=0, drop=True)
            )
    return df

############################################################
# ë©”ì¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
############################################################

def preprocess(train_path: Path, test_path: Path, info_path: Path, output_dir: Path):
    print("ğŸ“¥ ë°ì´í„° ë¡œë“œ ì¤‘ ...")
    train_df = pd.read_csv(train_path, parse_dates=["ì¼ì‹œ"], low_memory=False)
    test_df = pd.read_csv(test_path, parse_dates=["ì¼ì‹œ"], low_memory=False)
    info_df = pd.read_csv(info_path)

    # dtype ì„¤ì •
    train_df["ê±´ë¬¼ë²ˆí˜¸"] = train_df["ê±´ë¬¼ë²ˆí˜¸"].astype("category")
    test_df["ê±´ë¬¼ë²ˆí˜¸"] = test_df["ê±´ë¬¼ë²ˆí˜¸"].astype("category")
    info_df["ê±´ë¬¼ë²ˆí˜¸"] = info_df["ê±´ë¬¼ë²ˆí˜¸"].astype("category")
    info_df["ê±´ë¬¼ìœ í˜•"] = info_df["ê±´ë¬¼ìœ í˜•"].astype("category")

    ########################################################
    # 1) ê²°ì¸¡ì¹˜ ê¸°í˜¸ "-" ì²˜ë¦¬ ë° í”Œë˜ê·¸ ìƒì„±
    ########################################################
    miss_cols = ["íƒœì–‘ê´‘ìš©ëŸ‰(kW)", "ESSì €ì¥ìš©ëŸ‰(kWh)", "PCSìš©ëŸ‰(kW)"]
    for c in miss_cols:
        info_df[f"{c}_missing"] = (info_df[c] == "-").astype(int)
    num_cols = ["ì—°ë©´ì (m2)", "ëƒ‰ë°©ë©´ì (m2)"] + miss_cols
    info_df[num_cols] = info_df[num_cols].replace("-", np.nan).astype(float)

    # ê±´ë¬¼ìœ í˜•ë³„ ì¤‘ì•™ê°’ìœ¼ë¡œ ë³´ê°„
    for col in num_cols:
        info_df[col] = info_df.groupby("ê±´ë¬¼ìœ í˜•")[col].transform(lambda x: x.fillna(x.median()))

    ########################################################
    # 2) train / test í•©ì¹˜ê¸° & ì „ë ¥ì†Œë¹„ í´ë¦¬í•‘
    ########################################################
    test_df["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"] = np.nan
    all_df = pd.concat([train_df, test_df], ignore_index=True)
    all_df = all_df.merge(info_df, on="ê±´ë¬¼ë²ˆí˜¸", how="left")

    # ìŒìˆ˜ ì œê±°, ê·¹ë‹¨ì¹˜ winsorize
    all_df["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"] = all_df["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].clip(lower=0)
    # winsorize per building (99.5 pct)
    def _winsorize(group):
        if group.isna().all():
            return group
        cap = group.quantile(0.995)
        return group.clip(upper=cap)
    all_df["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"] = all_df.groupby("ê±´ë¬¼ë²ˆí˜¸")["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].transform(_winsorize)

    ########################################################
    # 3) Hampel í•„í„° (log-space) â€“ train ì˜ì—­ë§Œ ì ìš©
    ########################################################
    mask_train = ~all_df["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].isna()
    temp_series = np.log1p(all_df.loc[mask_train, "ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"])
    all_df.loc[mask_train, "ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"] = np.expm1(hampel_filter(temp_series))

    ########################################################
    # 4) íƒ€ê²Ÿ ë³€í™˜ & ë©´ì /ìš©ëŸ‰ ë¡œê·¸ ë³€í™˜
    ########################################################
    all_df["log_power"] = np.log1p(all_df["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"])
    for col in ["ì—°ë©´ì (m2)", "ëƒ‰ë°©ë©´ì (m2)", "íƒœì–‘ê´‘ìš©ëŸ‰(kW)", "ESSì €ì¥ìš©ëŸ‰(kWh)", "PCSìš©ëŸ‰(kW)"]:
        all_df[f"log_{col}"] = np.log1p(all_df[col])
    all_df["cooling_ratio"] = all_df["ëƒ‰ë°©ë©´ì (m2)"] / (all_df["ì—°ë©´ì (m2)"] + 1e-6)

    ########################################################
    # 5) ì‹œê°„ & ë‚ ì”¨ íŒŒìƒ
    ########################################################
    all_df = add_time_features(all_df)
    all_df = add_weather_features(all_df)

    ########################################################
    # 6) ì‹œì°¨ / ë¡¤ë§ í”¼ì²˜ (ì£¼ìš” ë³€ìˆ˜)
    ########################################################
    all_df = create_lag_rolling(
        all_df,
        group_cols=["ê±´ë¬¼ë²ˆí˜¸"],
        target_cols=["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)", "ê¸°ì˜¨(Â°C)", "ìŠµë„(%)"]
    )

    ########################################################
    # 7) ê³ ê¸‰ ê¸°ìƒ í”¼ì²˜ ìƒì„± (3ìœ„ ì½”ë“œ ì•„ì´ë””ì–´)
    ########################################################
    print("ê³ ê¸‰ ê¸°ìƒ í”¼ì²˜ ìƒì„± ì¤‘...")
    
    # CDH (Cooling Degree Hours) - ëƒ‰ë°©ë„ì‹œ: 26ë„ ì´ìƒ ëˆ„ì  ì˜¨ë„
    def calculate_cdh(df):
        cdh_values = []
        for building_id in df["ê±´ë¬¼ë²ˆí˜¸"].unique():
            building_data = df[df["ê±´ë¬¼ë²ˆí˜¸"] == building_id].sort_values("ì¼ì‹œ")
            temp_values = building_data["ê¸°ì˜¨(Â°C)"].values
            # 26ë„ ê¸°ì¤€ ëƒ‰ë°©ë„ì‹œ ê³„ì‚° (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)
            cumsum = np.cumsum(np.maximum(temp_values - 26, 0))
            # 11ì‹œê°„ ìœˆë„ìš°ë¡œ CDH ê³„ì‚°
            cdh = np.concatenate([
                cumsum[:11] if len(cumsum) > 11 else cumsum,
                cumsum[11:] - cumsum[:-11] if len(cumsum) > 11 else []
            ])
            cdh_values.extend(cdh)
        return cdh_values
    
    all_df["CDH"] = calculate_cdh(all_df)
    
    # THI (Temperature-Humidity Index) - ë¶ˆì¾Œì§€ìˆ˜
    all_df["THI"] = (9/5 * all_df["ê¸°ì˜¨(Â°C)"] - 
                     0.55 * (1 - all_df["ìŠµë„(%)"] / 100) * 
                     (9/5 * all_df["ê¸°ì˜¨(Â°C)"] - 26) + 32)
    
    # WCT (Wind Chill Temperature) - ì²´ê°ì˜¨ë„
    all_df["WCT"] = (13.12 + 0.6125 * all_df["ê¸°ì˜¨(Â°C)"] - 
                     11.37 * (all_df["í’ì†(m/s)"] ** 0.16) + 
                     0.3965 * (all_df["í’ì†(m/s)"] ** 0.16) * all_df["ê¸°ì˜¨(Â°C)"])
    
    print(f"âœ… ê³ ê¸‰ ê¸°ìƒ í”¼ì²˜ ìƒì„± ì™„ë£Œ: CDH, THI, WCT")

    ########################################################
    # 8) í†µê³„ ê¸°ë°˜ í”¼ì²˜ ìƒì„± (ê³¼ê±° íŒ¨í„´ í•™ìŠµ)
    ########################################################
    print("í†µê³„ ê¸°ë°˜ í”¼ì²˜ ìƒì„± ì¤‘...")
    
    # Train ë°ì´í„°ë§Œìœ¼ë¡œ í†µê³„ ê³„ì‚° (ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€)
    train_mask = ~all_df["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].isna()
    train_stats = all_df[train_mask].copy()
    
    # ê±´ë¬¼Ã—ì‹œê°„Ã—ìš”ì¼ í†µê³„
    building_hour_weekday_stats = train_stats.groupby(
        ["ê±´ë¬¼ë²ˆí˜¸", "hour", "weekday"]
    )["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].agg(["mean", "std"]).reset_index()
    building_hour_weekday_stats.columns = [
        "ê±´ë¬¼ë²ˆí˜¸", "hour", "weekday", "building_hour_weekday_mean", "building_hour_weekday_std"
    ]
    
    # ê±´ë¬¼Ã—ì‹œê°„ í†µê³„  
    building_hour_stats = train_stats.groupby(
        ["ê±´ë¬¼ë²ˆí˜¸", "hour"]
    )["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].agg(["mean", "std"]).reset_index()
    building_hour_stats.columns = [
        "ê±´ë¬¼ë²ˆí˜¸", "hour", "building_hour_mean", "building_hour_std"
    ]
    
    # ê±´ë¬¼Ã—ì›” í†µê³„ (ê³„ì ˆì„±)
    building_month_stats = train_stats.groupby(
        ["ê±´ë¬¼ë²ˆí˜¸", "month"]
    )["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].agg(["mean", "std"]).reset_index()
    building_month_stats.columns = [
        "ê±´ë¬¼ë²ˆí˜¸", "month", "building_month_mean", "building_month_std"
    ]
    
    # ì „ì²´ ë°ì´í„°ì— í†µê³„ í”¼ì²˜ ë³‘í•©
    all_df = all_df.merge(building_hour_weekday_stats, on=["ê±´ë¬¼ë²ˆí˜¸", "hour", "weekday"], how="left")
    all_df = all_df.merge(building_hour_stats, on=["ê±´ë¬¼ë²ˆí˜¸", "hour"], how="left")
    all_df = all_df.merge(building_month_stats, on=["ê±´ë¬¼ë²ˆí˜¸", "month"], how="left")
    
    # NaN ê°’ ì²˜ë¦¬ (ìƒˆë¡œìš´ ì¡°í•©ì˜ ê²½ìš° ì „ì²´ í‰ê· ìœ¼ë¡œ ëŒ€ì²´)
    overall_mean = train_stats["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].mean()
    overall_std = train_stats["ì „ë ¥ì†Œë¹„ëŸ‰(kWh)"].std()
    
    stat_cols = [
        "building_hour_weekday_mean", "building_hour_weekday_std",
        "building_hour_mean", "building_hour_std", 
        "building_month_mean", "building_month_std"
    ]
    
    for col in stat_cols:
        if "mean" in col:
            all_df[col] = all_df[col].fillna(overall_mean)
        else:  # std
            all_df[col] = all_df[col].fillna(overall_std)
    
    print(f"âœ… í†µê³„ ê¸°ë°˜ í”¼ì²˜ ìƒì„± ì™„ë£Œ: {len(stat_cols)}ê°œ í”¼ì²˜")

    ########################################################
    # 9) ë²”ì£¼í˜• temp_bin, ê±´ë¬¼ìœ í˜•, ê±´ë¬¼ë²ˆí˜¸ ìœ ì§€
    ########################################################
    all_df["temp_bin"] = all_df["temp_bin"].astype("category")

    ########################################################
    # 10) ìºì‹± â€“ train / test ë¶„ë¦¬ ì €ì¥
    ########################################################
    output_dir.mkdir(parents=True, exist_ok=True)
    df_train = all_df[mask_train].copy()
    df_test = all_df[~mask_train].copy()
    train_out = output_dir / "train_preprocessed.parquet"
    test_out = output_dir / "test_preprocessed.parquet"
    df_train.to_parquet(train_out, index=False)
    df_test.to_parquet(test_out, index=False)
    print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ â†’ {train_out.name}, {test_out.name} ì €ì¥")

############################################################
# CLI
############################################################

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ì—ë„ˆì§€ ì†Œë¹„ ì˜ˆì¸¡ìš© ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ (method_04)")
    parser.add_argument("--train", type=Path, default=Path("data/train.csv"))
    parser.add_argument("--test", type=Path, default=Path("data/test.csv"))
    parser.add_argument("--info", type=Path, default=Path("data/building_info.csv"))
    parser.add_argument("--out", type=Path, default=Path("method_04/cache"))
    args = parser.parse_args()

    preprocess(args.train, args.test, args.info, args.out) 