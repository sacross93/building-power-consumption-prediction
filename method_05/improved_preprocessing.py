"""
Improved Data Preprocessing Based on Visualization Analysis
==========================================================

ì‹œê°í™” ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì„ ëœ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:
1. íƒ€ê²Ÿ ë³€ìˆ˜ log ë³€í™˜
2. VIF ê¸°ë°˜ ë‹¤ì¤‘ê³µì„ ì„± ì œê±°
3. í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
4. ì´ìƒê°’ ì²˜ë¦¬
5. ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, QuantileTransformer
from sklearn.feature_selection import SelectKBest, f_regression
from statsmodels.stats.outliers_influence import variance_inflation_factor
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

from solution import load_data, engineer_features


class ImprovedPreprocessor:
    """ê°œì„ ëœ ì „ì²˜ë¦¬ í´ë˜ìŠ¤."""
    
    def __init__(self, scaler_type='standard'):
        """
        Parameters:
        -----------
        scaler_type : str
            'standard' (ê¸°ë³¸ê°’), 'robust', 'minmax', 'quantile' ì¤‘ ì„ íƒ
        """
        self.scaler_type = scaler_type
        self.scaler = None
        self.selected_features = None
        self.outlier_bounds = {}
        self.target_transformer = None
        
    def detect_outliers_iqr(self, data, column, factor=1.5):
        """IQR ê¸°ë°˜ ì´ìƒê°’ íƒì§€."""
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - factor * IQR
        upper_bound = Q3 + factor * IQR
        
        outliers = (data[column] < lower_bound) | (data[column] > upper_bound)
        
        return outliers, lower_bound, upper_bound
    
    def remove_multicollinearity(self, X, threshold=10.0):
        """VIF ê¸°ë°˜ ë‹¤ì¤‘ê³µì„ ì„± ì œê±°."""
        print(f"Removing multicollinearity (VIF > {threshold})...")
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì„ íƒ
        numeric_cols = X.select_dtypes(include=[np.number]).columns
        X_numeric = X[numeric_cols].copy()
        
        # ë¬´í•œê°’ì´ë‚˜ NaN ì œê±°
        X_numeric = X_numeric.replace([np.inf, -np.inf], np.nan).dropna(axis=1)
        
        if X_numeric.empty:
            print("No valid numeric columns for VIF analysis")
            return X.columns.tolist()
        
        # ìƒìˆ˜ ì»¬ëŸ¼ ì œê±°
        constant_cols = [col for col in X_numeric.columns if X_numeric[col].var() == 0]
        X_numeric = X_numeric.drop(columns=constant_cols)
        
        if X_numeric.empty:
            print("No non-constant columns for VIF analysis")
            return X.columns.tolist()
        
        features_to_keep = list(X_numeric.columns)
        
        while True:
            if len(features_to_keep) <= 1:
                break
                
            try:
                # ìˆ«ìí˜• ë°ì´í„°ë§Œ í•„í„°ë§í•˜ê³  ë¬´í•œê°’/NaN ì²˜ë¦¬
                X_vif = X_numeric[features_to_keep].copy()
                
                # ë¬´í•œê°’ê³¼ NaNì„ 0ìœ¼ë¡œ ëŒ€ì²´
                X_vif = X_vif.replace([np.inf, -np.inf], np.nan).fillna(0)
                
                # ìƒìˆ˜ ì»¬ëŸ¼ ì œê±° (ë¶„ì‚°ì´ 0ì¸ ì»¬ëŸ¼)
                constant_cols = X_vif.columns[X_vif.var() == 0].tolist()
                if constant_cols:
                    features_to_keep = [f for f in features_to_keep if f not in constant_cols]
                    print(f"Removed constant columns: {constant_cols}")
                    continue
                
                # VIF ê³„ì‚°
                vif_df = pd.DataFrame()
                vif_df["Feature"] = features_to_keep
                vif_df["VIF"] = [
                    variance_inflation_factor(X_vif.values, i) 
                    for i in range(len(features_to_keep))
                ]
                
                # ë¬´í•œê°’ VIF ì²˜ë¦¬
                vif_df["VIF"] = vif_df["VIF"].replace([np.inf, -np.inf], 999999)
                
                # ìµœê³  VIFê°€ ì„ê³„ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ ì¤‘ë‹¨
                max_vif = vif_df["VIF"].max()
                if max_vif <= threshold:
                    break
                
                # ê°€ì¥ ë†’ì€ VIFë¥¼ ê°€ì§„ í”¼ì²˜ ì œê±°
                feature_to_remove = vif_df.loc[vif_df["VIF"].idxmax(), "Feature"]
                features_to_keep.remove(feature_to_remove)
                print(f"Removed {feature_to_remove} (VIF: {max_vif:.2f})")
                
            except Exception as e:
                print(f"VIF calculation error: {e}")
                break
        
        # ë¹„ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë“¤ë„ í¬í•¨
        non_numeric_cols = [col for col in X.columns if col not in numeric_cols]
        final_features = features_to_keep + non_numeric_cols
        
        print(f"Features after multicollinearity removal: {len(final_features)}")
        return final_features
    
    def transform_target(self, y, method='log1p'):
        """íƒ€ê²Ÿ ë³€ìˆ˜ ë³€í™˜."""
        print(f"Applying {method} transformation to target variable...")
        
        if method == 'log1p':
            y_transformed = np.log1p(y)
        elif method == 'sqrt':
            y_transformed = np.sqrt(np.maximum(y, 0))
        else:
            y_transformed = y
            
        self.target_transformer = method
        return y_transformed
    
    def inverse_transform_target(self, y_transformed):
        """íƒ€ê²Ÿ ë³€ìˆ˜ ì—­ë³€í™˜."""
        if self.target_transformer == 'log1p':
            return np.expm1(y_transformed)
        elif self.target_transformer == 'sqrt':
            return np.power(y_transformed, 2)
        else:
            return y_transformed
    
    def create_advanced_features(self, df):
        """ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§."""
        print("Creating advanced features...")
        df = df.copy()
        
        # ì˜¨ë„ degree-day ê³„ì‚°
        if 'temp' in df.columns:
            # Cooling Degree Days (ê¸°ì¤€: 18Â°C)
            df['cdd'] = np.maximum(df['temp'] - 18, 0)
            # Heating Degree Days (ê¸°ì¤€: 18Â°C)  
            df['hdd'] = np.maximum(18 - df['temp'], 0)
            
            # ì˜¨ë„ ë³€ë™ì„± (ì¼ì¼ ë²”ìœ„ ì¶”ì •)
            df['temp_volatility'] = np.abs(df['temp'] - df['temp'].rolling(24, min_periods=1).mean())
            
            # ê³„ì ˆë³„ ì˜¨ë„ í¸ì°¨
            seasonal_temp = df.groupby('month')['temp'].transform('mean')
            df['temp_seasonal_deviation'] = df['temp'] - seasonal_temp
        
        # ìŠµë„ ê´€ë ¨ ê³ ê¸‰ í”¼ì²˜
        if 'humidity' in df.columns and 'temp' in df.columns:
            # ë¶ˆì¾Œì§€ìˆ˜ (ì‹¤ì œ ê³µì‹)
            df['heat_index'] = df['temp'] + 0.348 * df['humidity'] - 42.379
            
            # ìŠµë„ êµ¬ê°„ë³„ ì¸ë””ì¼€ì´í„°
            df['humidity_very_low'] = (df['humidity'] < 20).astype(int)
            df['humidity_optimal'] = ((df['humidity'] >= 40) & (df['humidity'] <= 60)).astype(int)
            df['humidity_very_high'] = (df['humidity'] > 80).astype(int)
        
        # ê±´ë¬¼ íš¨ìœ¨ì„± ê³ ê¸‰ í”¼ì²˜
        if 'total_area' in df.columns and 'pv_capacity' in df.columns:
            # ê±´ë¬¼ ì—ë„ˆì§€ íš¨ìœ¨ì„± ì ìˆ˜
            df['energy_efficiency_score'] = (
                df['pv_capacity'] / np.maximum(df['total_area'], 1) * 1000 +
                df['area_ratio'] * 50
            )
            
            # ê±´ë¬¼ í¬ê¸°ë³„ ì¹´í…Œê³ ë¦¬ (ë” ì„¸ë¶„í™”)
            df['building_size_category'] = pd.cut(
                df['total_area'], 
                bins=[0, 1000, 5000, 20000, 50000, np.inf],
                labels=['very_small', 'small', 'medium', 'large', 'very_large']
            )
        
        # ì‹œê°„ ê¸°ë°˜ ê³ ê¸‰ í”¼ì²˜
        if 'datetime' in df.columns:
            # í•œêµ­ ê³µíœ´ì¼ (ê°„ë‹¨í•œ ë²„ì „)
            df['is_holiday'] = (
                ((df['month'] == 8) & (df['day'] == 15)) |  # ê´‘ë³µì ˆ
                ((df['month'] == 6) & (df['day'] == 6))     # í˜„ì¶©ì¼
            ).astype(int)
            
            # ê³„ì ˆ êµ¬ë¶„ (ë” ì •í™•í•œ)
            df['season_detailed'] = pd.cut(
                df['month'], 
                bins=[0, 2, 5, 8, 11, 12],
                labels=['winter', 'spring', 'summer', 'fall', 'winter2'],
                ordered=False
            )
            
            # ì£¼ì°¨ ì •ë³´
            df['week_of_year'] = df['datetime'].dt.isocalendar().week
            
            # ì›” ë‚´ ì£¼ì°¨
            df['week_of_month'] = (df['day'] - 1) // 7 + 1
        
        # ê±´ë¬¼ íƒ€ì…ë³„ íŠ¹í™” í”¼ì²˜
        if 'building_type' in df.columns:
            # IDC ê±´ë¬¼ì˜ ì•¼ê°„ íŠ¹ì„±
            df['idc_night_operation'] = (
                (df['building_type'] == 'IDC(ì „í™”êµ­)') & 
                ((df['hour'] < 6) | (df['hour'] > 22))
            ).astype(int)
            
            # ë°±í™”ì ì˜ ì˜ì—…ì‹œê°„ íŠ¹ì„±
            df['department_store_hours'] = (
                (df['building_type'] == 'ë°±í™”ì ') &
                (df['hour'].between(10, 21)) &
                (df['weekday'] < 5)
            ).astype(int)
            
            # í•™êµì˜ ë°©í•™ ê¸°ê°„ (ì—¬ë¦„ë°©í•™ ì¶”ì •)
            df['school_vacation'] = (
                (df['building_type'] == 'í•™êµ') &
                (df['month'].isin([7, 8]))
            ).astype(int)
        
        print(f"Advanced features created. New shape: {df.shape}")
        return df
    
    def fit_transform(self, train_df, test_df, target_col='ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'):
        """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì ìš©."""
        print("=" * 80)
        print("IMPROVED PREPROCESSING PIPELINE")
        print("=" * 80)
        
        # 1. ê¸°ë³¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ê¸°ì¡´ solution.py) - ì´ë¯¸ ì ìš©ëœ ê²½ìš° ê±´ë„ˆë›°ê¸°
        print("1. Basic feature engineering...")
        if 'sunshine_est' in train_df.columns:
            # ì´ë¯¸ ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ì´ ì ìš©ëœ ë°ì´í„°
            print("   Already processed data detected, skipping basic FE...")
            train_processed, test_processed = train_df.copy(), test_df.copy()
        else:
            # ì›ë³¸ ë°ì´í„°, ê¸°ë³¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì ìš©
            train_processed, test_processed = engineer_features(train_df.copy(), test_df.copy())
        
        # 2. ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
        print("2. Advanced feature engineering...")
        train_processed = self.create_advanced_features(train_processed)
        test_processed = self.create_advanced_features(test_processed)
        
        # 3. íƒ€ê²Ÿ ë³€ìˆ˜ ì´ìƒê°’ íƒì§€ ë° ì²˜ë¦¬
        print("3. Target outlier detection...")
        if target_col in train_processed.columns:
            outliers, lower, upper = self.detect_outliers_iqr(train_processed, target_col, factor=2.0)
            print(f"Found {outliers.sum()} outliers in target variable")
            print(f"Outlier bounds: {lower:.2f} - {upper:.2f}")
            
            # ì´ìƒê°’ ìº¡í•‘ (ì™„ì „ ì œê±°ë³´ë‹¤ëŠ” ìº¡í•‘)
            train_processed[target_col] = np.clip(
                train_processed[target_col], 
                lower, upper
            )
            
            self.outlier_bounds[target_col] = (lower, upper)
        
        # 4. íƒ€ê²Ÿ ë³€ìˆ˜ ë³€í™˜
        print("4. Target transformation...")
        if target_col in train_processed.columns:
            y_original = train_processed[target_col].copy()
            y_transformed = self.transform_target(y_original, method='log1p')
            train_processed[f'{target_col}_log'] = y_transformed
            
            # ë³€í™˜ íš¨ê³¼ ì¶œë ¥
            print(f"Original target - Mean: {y_original.mean():.2f}, Std: {y_original.std():.2f}")
            print(f"Transformed target - Mean: {y_transformed.mean():.2f}, Std: {y_transformed.std():.2f}")
        
        # 5. í”¼ì²˜ ì¤€ë¹„
        print("5. Feature preparation...")
        drop_cols = [target_col, f'{target_col}_log', 'ì¼ì‹œ', 'num_date_time', 'datetime']
        feature_cols = [c for c in train_processed.columns if c not in drop_cols and c in test_processed.columns]
        
        X_train = train_processed[feature_cols].copy()
        X_test = test_processed[feature_cols].copy()
        
        # 6. ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ ì²˜ë¦¬
        print("6. Categorical encoding...")
        categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns
        
        for col in categorical_cols:
            # ë¼ë²¨ ì¸ì½”ë”©
            all_categories = pd.concat([X_train[col], X_test[col]]).astype(str).unique()
            category_map = {cat: idx for idx, cat in enumerate(all_categories)}
            
            X_train[col] = X_train[col].astype(str).map(category_map).fillna(-1)
            X_test[col] = X_test[col].astype(str).map(category_map).fillna(-1)
        
        # 7. ë‹¤ì¤‘ê³µì„ ì„± ì œê±°
        print("7. Multicollinearity removal...")
        selected_features = self.remove_multicollinearity(X_train, threshold=10.0)
        X_train = X_train[selected_features]
        X_test = X_test[selected_features]
        self.selected_features = selected_features
        
        # 8. í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
        print("8. Feature scaling...")
        scaler_map = {
            'standard': StandardScaler(),
            'robust': RobustScaler(), 
            'minmax': MinMaxScaler(),
            'quantile': QuantileTransformer(n_quantiles=100, random_state=42)
        }
        
        self.scaler = scaler_map.get(self.scaler_type, StandardScaler())
        print(f"   Using {self.scaler.__class__.__name__}...")
        
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        X_train_scaled = pd.DataFrame(X_train_scaled, columns=selected_features, index=X_train.index)
        X_test_scaled = pd.DataFrame(X_test_scaled, columns=selected_features, index=X_test.index)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nâœ… Preprocessing completed!")
        print(f"Original features: {len(feature_cols)}")
        print(f"Selected features: {len(selected_features)}")
        print(f"Final train shape: {X_train_scaled.shape}")
        print(f"Final test shape: {X_test_scaled.shape}")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ë°˜í™˜
        if target_col in train_processed.columns:
            return X_train_scaled, X_test_scaled, train_processed[f'{target_col}_log']
        else:
            return X_train_scaled, X_test_scaled, None
    
    def create_preprocessing_report(self, output_dir='./visualizations/'):
        """ì „ì²˜ë¦¬ ê°œì„  ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±."""
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)
        
        report_path = output_dir / 'improved_preprocessing_report.md'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# Improved Preprocessing Report\n\n")
            
            f.write("## Applied Improvements\n\n")
            
            f.write("### 1. Target Variable Transformation\n")
            f.write(f"- Method: {self.target_transformer}\n")
            f.write("- Reduces right-skewness for better model training\n\n")
            
            if self.outlier_bounds:
                f.write("### 2. Outlier Treatment\n")
                for col, bounds in self.outlier_bounds.items():
                    f.write(f"- {col}: Clipped to [{bounds[0]:.2f}, {bounds[1]:.2f}]\n")
                f.write("\n")
            
            f.write("### 3. Multicollinearity Removal\n")
            if self.selected_features:
                f.write(f"- Features selected: {len(self.selected_features)}\n")
                f.write(f"- VIF threshold: 10.0\n\n")
            
            f.write("### 4. Feature Scaling\n")
            f.write(f"- Method: {type(self.scaler).__name__}\n")
            f.write("- Robust to outliers, normalizes feature scales\n\n")
            
            f.write("### 5. Advanced Feature Engineering\n")
            f.write("- Cooling/Heating Degree Days\n")
            f.write("- Heat Index calculation\n")
            f.write("- Building efficiency scores\n")
            f.write("- Holiday indicators\n")
            f.write("- Building-type specific features\n\n")
            
            f.write("## Expected Benefits\n\n")
            f.write("1. **Better model convergence** from target transformation\n")
            f.write("2. **Reduced overfitting** from multicollinearity removal\n")
            f.write("3. **Improved gradient flow** from feature scaling\n")
            f.write("4. **Enhanced feature richness** from advanced engineering\n")
            f.write("5. **More robust predictions** from outlier handling\n")
        
        print(f"ğŸ“„ Preprocessing report saved: {report_path}")


def test_improved_preprocessing():
    """ê°œì„ ëœ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸."""
    print("Testing improved preprocessing pipeline...")
    
    # ë°ì´í„° ë¡œë“œ
    data_dir = Path('../data')
    train_path = data_dir / 'train.csv'
    test_path = data_dir / 'test.csv'
    building_path = data_dir / 'building_info.csv'
    
    train_df, test_df = load_data(train_path, test_path, building_path)
    
    # ê°œì„ ëœ ì „ì²˜ë¦¬ ì ìš©
    preprocessor = ImprovedPreprocessor()
    X_train, X_test, y_train = preprocessor.fit_transform(train_df, test_df)
    
    # ê²°ê³¼ ë¶„ì„
    print("\n" + "=" * 60)
    print("PREPROCESSING RESULTS ANALYSIS")
    print("=" * 60)
    
    print(f"Training features shape: {X_train.shape}")
    print(f"Test features shape: {X_test.shape}")
    if y_train is not None:
        print(f"Target variable shape: {y_train.shape}")
        print(f"Target stats - Mean: {y_train.mean():.4f}, Std: {y_train.std():.4f}")
    
    # í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ (ê°„ë‹¨í•œ ìƒê´€ê´€ê³„)
    if y_train is not None:
        correlations = X_train.corrwith(y_train).abs().sort_values(ascending=False)
        print(f"\nTop 10 feature correlations with transformed target:")
        for i, (feature, corr) in enumerate(correlations.head(10).items()):
            print(f"{i+1:2d}. {feature}: {corr:.4f}")
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    preprocessor.create_preprocessing_report()
    
    return X_train, X_test, y_train, preprocessor


if __name__ == "__main__":
    X_train, X_test, y_train, preprocessor = test_improved_preprocessing()
    print("\nğŸ¯ Improved preprocessing completed successfully!")