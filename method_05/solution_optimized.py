"""
Optimized solution based on solution_backup.py
7-8 SMAPE â†’ 5-6 SMAPE ëª©í‘œ
GPU ì„œë²„ ì „ìš©
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
import xgboost as xgb
import lightgbm as lgb
from sklearn.ensemble import VotingRegressor
import warnings
warnings.filterwarnings('ignore')

def smape(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """Compute the Symmetric Mean Absolute Percentage Error (SMAPE)."""
    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))

def load_data(train_path: Path, test_path: Path, building_path: Path) -> tuple[pd.DataFrame, pd.DataFrame]:
    """Load and merge data (ì›ë³¸ê³¼ ë™ì¼)."""
    # Column renaming map to avoid special characters
    rename_map = {
        'ê¸°ì˜¨(Â°C)': 'temp',
        'ê°•ìˆ˜ëŸ‰(mm)': 'rainfall',
        'í’ì†(m/s)': 'wind_speed',
        'ìŠµë„(%)': 'humidity',
        'ì¼ì¡°(hr)': 'sunshine_hours',
        'ì¼ì‚¬(MJ/m2)': 'solar_radiation',
        'ì—°ë©´ì (m2)': 'total_area',
        'ëƒ‰ë°©ë©´ì (m2)': 'cooling_area',
        'íƒœì–‘ê´‘ìš©ëŸ‰(kW)': 'pv_capacity',
        'ESSì €ì¥ìš©ëŸ‰(kWh)': 'ess_capacity',
        'PCSìš©ëŸ‰(kW)': 'pcs_capacity',
        'ê±´ë¬¼ìœ í˜•': 'building_type',
    }
    
    # Load CSVs
    train = pd.read_csv(train_path, encoding='utf-8-sig')
    test = pd.read_csv(test_path, encoding='utf-8-sig')
    building_info = pd.read_csv(building_path, encoding='utf-8-sig')
    
    # Rename columns
    train.rename(columns=rename_map, inplace=True)
    test.rename(columns=rename_map, inplace=True)
    building_info.rename(columns=rename_map, inplace=True)
    
    # Merge building info
    train = train.merge(building_info, on='ê±´ë¬¼ë²ˆí˜¸', how='left')
    test = test.merge(building_info, on='ê±´ë¬¼ë²ˆí˜¸', how='left')
    
    return train, test

def engineer_features(train: pd.DataFrame, test: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:
    """Enhanced feature engineering for better performance."""
    # ê¸°ì¡´ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ì›ë³¸ê³¼ ë™ì¼)
    train['datetime'] = pd.to_datetime(train['ì¼ì‹œ'], format='%Y%m%d %H')
    test['datetime'] = pd.to_datetime(test['ì¼ì‹œ'], format='%Y%m%d %H')
    
    for df in (train, test):
        df['year'] = df['datetime'].dt.year
        df['month'] = df['datetime'].dt.month
        df['day'] = df['datetime'].dt.day
        df['hour'] = df['datetime'].dt.hour
        df['weekday'] = df['datetime'].dt.weekday
        df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)
    
    # Missing value imputation (handle '-' strings)
    for col in ['total_area', 'cooling_area', 'pv_capacity', 'ess_capacity', 'pcs_capacity']:
        # Replace '-' with NaN and convert to numeric
        train[col] = pd.to_numeric(train[col].replace('-', np.nan), errors='coerce')
        test[col] = pd.to_numeric(test[col].replace('-', np.nan), errors='coerce')
        
        # Fill with median
        median = train[col].median()
        train[col] = train[col].fillna(median)
        test[col] = test[col].fillna(median)
    
    # Sunshine and solar radiation approximation
    train_august = train[train['month'] == 8]
    avg_sunshine = train_august.groupby('hour')['sunshine_hours'].mean()
    avg_solar = train_august.groupby('hour')['solar_radiation'].mean()
    
    train['sunshine_est'] = train['sunshine_hours']
    train['solar_est'] = train['solar_radiation']
    test['sunshine_est'] = test['hour'].map(avg_sunshine)
    test['solar_est'] = test['hour'].map(avg_solar)
    
    train.drop(columns=['sunshine_hours', 'solar_radiation'], inplace=True)
    test.drop(columns=['sunshine_hours', 'solar_radiation'], inplace=True, errors='ignore')
    
    # Building-level statistics
    building_mean = train.groupby('ê±´ë¬¼ë²ˆí˜¸')['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'].mean()
    
    bld_hour_mean = (
        train.groupby(['ê±´ë¬¼ë²ˆí˜¸', 'hour'])['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
        .mean()
        .reset_index()
        .rename(columns={'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)': 'bld_hour_mean'})
    )
    train = train.merge(bld_hour_mean, on=['ê±´ë¬¼ë²ˆí˜¸', 'hour'], how='left')
    test = test.merge(bld_hour_mean, on=['ê±´ë¬¼ë²ˆí˜¸', 'hour'], how='left')
    test['bld_hour_mean'] = test['bld_hour_mean'].fillna(test['ê±´ë¬¼ë²ˆí˜¸'].map(building_mean))
    
    bld_wd_mean = (
        train.groupby(['ê±´ë¬¼ë²ˆí˜¸', 'weekday'])['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
        .mean()
        .reset_index()
        .rename(columns={'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)': 'bld_wd_mean'})
    )
    train = train.merge(bld_wd_mean, on=['ê±´ë¬¼ë²ˆí˜¸', 'weekday'], how='left')
    test = test.merge(bld_wd_mean, on=['ê±´ë¬¼ë²ˆí˜¸', 'weekday'], how='left')
    test['bld_wd_mean'] = test['bld_wd_mean'].fillna(test['ê±´ë¬¼ë²ˆí˜¸'].map(building_mean))
    
    bld_month_mean = (
        train.groupby(['ê±´ë¬¼ë²ˆí˜¸', 'month'])['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
        .mean()
        .reset_index()
        .rename(columns={'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)': 'bld_month_mean'})
    )
    train = train.merge(bld_month_mean, on=['ê±´ë¬¼ë²ˆí˜¸', 'month'], how='left')
    test = test.merge(bld_month_mean, on=['ê±´ë¬¼ë²ˆí˜¸', 'month'], how='left')
    test['bld_month_mean'] = test['bld_month_mean'].fillna(test['ê±´ë¬¼ë²ˆí˜¸'].map(building_mean))
    
    # Enhanced feature engineering for 5-6 SMAPE target
    for df in (train, test):
        # ê¸°ì¡´ í”¼ì²˜ë“¤
        df['area_ratio'] = df['cooling_area'] / df['total_area']
        df['pv_per_area'] = df['pv_capacity'] / df['total_area']
        df['humidity_temp'] = df['humidity'] * df['temp']
        df['rain_wind'] = df['rainfall'] * df['wind_speed']
        
        # ìƒˆë¡œìš´ ì„±ëŠ¥ í–¥ìƒ í”¼ì²˜ë“¤
        # 1. ìˆœí™˜ ì‹œê°„ í”¼ì²˜ (ë” ë¶€ë“œëŸ¬ìš´ ì‹œê°„ í‘œí˜„)
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)
        df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7)
        
        # 2. ì˜¨ë„ êµ¬ê°„ë³„ í”¼ì²˜
        df['temp_category'] = pd.cut(df['temp'], 
                                   bins=[-np.inf, 10, 20, 25, 30, np.inf], 
                                   labels=['very_cold', 'cold', 'mild', 'warm', 'hot'])
        
        # 3. ìŠµë„ êµ¬ê°„ë³„ í”¼ì²˜
        df['humidity_category'] = pd.cut(df['humidity'], 
                                       bins=[0, 40, 60, 80, 100], 
                                       labels=['dry', 'normal', 'humid', 'very_humid'])
        
        # 4. ë³µí•© í”¼ì²˜ë“¤
        df['comfort_index'] = df['temp'] * (1 - df['humidity'] / 100)  # ì²´ê°ì˜¨ë„
        df['energy_efficiency'] = (df['pv_capacity'] + 1) / (df['total_area'] + 1) * 1000
        df['cooling_ratio'] = df['cooling_area'] / (df['total_area'] + 1)
        
        # 5. ê±´ë¬¼ë³„-ì‹œê°„ë³„ ë³µí•© í”¼ì²˜
        df['bld_hour_interaction'] = df['bld_hour_mean'] * df['hour'] / 24
        df['bld_temp_interaction'] = df['bld_hour_mean'] * df['temp'] / 30
        
        # 6. ê³„ì ˆì„± í”¼ì²˜
        df['is_summer'] = df['month'].isin([6, 7, 8]).astype(int)
        df['is_winter'] = df['month'].isin([12, 1, 2]).astype(int)
        df['peak_hours'] = df['hour'].isin([10, 11, 14, 15, 16]).astype(int)
    
    return train, test

def build_ensemble_model(train: pd.DataFrame, test: pd.DataFrame, output_dir: Path) -> None:
    """Build ensemble model for 5-6 SMAPE target."""
    print("Building optimized ensemble model for 5-6 SMAPE target...")
    
    # Feature preparation
    feature_cols = [col for col in train.columns 
                   if col not in ['num_date_time', 'ê±´ë¬¼ë²ˆí˜¸', 'ì¼ì‹œ', 'datetime', 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']]
    
    X = train[feature_cols]
    y = train['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
    X_test = test[feature_cols]
    
    # Preprocessing
    categorical_features = ['building_type', 'temp_category', 'humidity_category']
    categorical_transformer = OneHotEncoder(handle_unknown='ignore', drop='first')
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', categorical_transformer, categorical_features)
        ],
        remainder='passthrough'
    )
    
    # 1. Optimized XGBoost (GPU)
    xgb_model = xgb.XGBRegressor(
        max_depth=10,
        n_estimators=1500,  # ë” ë§ì€ íŠ¸ë¦¬
        learning_rate=0.02,  # ë” ë‚®ì€ í•™ìŠµë¥ 
        subsample=0.9,
        colsample_bytree=0.9,
        colsample_bylevel=0.8,
        reg_alpha=0.2,
        reg_lambda=2.0,
        min_child_weight=3,
        objective='reg:squarederror',
        tree_method='gpu_hist',
        gpu_id=0,
        random_state=42,
    )
    
    # 2. Optimized LightGBM (GPU) 
    lgb_model = lgb.LGBMRegressor(
        max_depth=12,
        n_estimators=1800,
        learning_rate=0.015,
        subsample=0.9,
        colsample_bytree=0.9,
        reg_alpha=0.3,
        reg_lambda=2.5,
        num_leaves=300,
        min_child_samples=20,
        device='gpu',
        gpu_use_dp=True,
        random_state=42,
        verbosity=-1
    )
    
    # 3. Ensemble
    ensemble = VotingRegressor([
        ('xgb', Pipeline([('preprocess', preprocessor), ('model', xgb_model)])),
        ('lgb', Pipeline([('preprocess', preprocessor), ('model', lgb_model)]))
    ])
    
    # Validation split
    cutoff = pd.Timestamp('2024-08-18')
    train_mask = train['datetime'] < cutoff
    val_mask = ~train_mask
    X_train, y_train = X.loc[train_mask], y.loc[train_mask]
    X_val, y_val = X.loc[val_mask], y.loc[val_mask]
    
    print(f"Training features: {X_train.shape}")
    print(f"Validation features: {X_val.shape}")
    
    # Train ensemble
    print("Training ensemble model...")
    ensemble.fit(X_train, y_train)
    
    # Validation
    val_pred = ensemble.predict(X_val)
    val_smape = smape(y_val.values, val_pred)
    print(f"Validation SMAPE: {val_smape:.4f}")
    
    # Final training on full data
    print("Final training on full dataset...")
    ensemble.fit(X, y)
    
    # Predictions
    test_pred = ensemble.predict(X_test)
    
    # Save results
    validation_path = output_dir / 'optimized_validation.txt'
    with validation_path.open('w') as f:
        f.write(f'Optimized Validation SMAPE: {val_smape:.6f}%\n')
        f.write(f'Target: 5-6 SMAPE\n')
        f.write(f'Features used: {len(feature_cols)}\n')
    
    submission = test[['num_date_time']].copy()
    submission['answer'] = test_pred
    submission.to_csv(output_dir / 'submission_optimized.csv', index=False)
    
    print(f"âœ… Optimized model completed!")
    print(f"ğŸ“Š Validation SMAPE: {val_smape:.4f} (Target: 5-6)")
    print(f"ğŸ’¾ Submission saved: submission_optimized.csv")
    
    return val_smape

def main() -> None:
    """Main execution function."""
    print("=" * 60)
    print("OPTIMIZED SOLUTION: 7-8 SMAPE â†’ 5-6 SMAPE")
    print("Based on solution_backup.py + GPU optimization")
    print("=" * 60)
    
    base_dir = Path('../data')
    train_path = base_dir / 'train.csv'
    test_path = base_dir / 'test.csv'
    building_path = base_dir / 'building_info.csv'
    
    # Load and engineer features
    train_df, test_df = load_data(train_path, test_path, building_path)
    train_fe, test_fe = engineer_features(train_df, test_df)
    
    # Build and train optimized model
    result = build_ensemble_model(train_fe, test_fe, Path('.'))
    
    print(f"\nğŸ¯ Mission: Convert 7-8 SMAPE â†’ 5-6 SMAPE")
    print(f"ğŸš€ Result: {result:.4f} SMAPE")
    
    if result < 6.0:
        print("ğŸ‰ SUCCESS! Target achieved!")
    elif result < 7.0:
        print("âœ… Good progress! Close to target.")
    else:
        print("ğŸ“ˆ Need more optimization.")

if __name__ == "__main__":
    main()