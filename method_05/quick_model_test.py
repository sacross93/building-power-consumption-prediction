"""
Quick Model Performance Test
===========================

ë¹ ë¥¸ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (1-fold êµì°¨ê²€ì¦)
"""

import pandas as pd
import numpy as np
from pathlib import Path
import xgboost as xgb
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

from solution import load_data, engineer_features, smape
from ts_validation import TimeSeriesCV
from improved_preprocessing import ImprovedPreprocessor


def quick_test():
    """ë¹ ë¥¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸."""
    print("=" * 60)
    print("QUICK MODEL PERFORMANCE TEST")
    print("=" * 60)
    
    # ë°ì´í„° ë¡œë“œ
    data_dir = Path('../data')
    train_path = data_dir / 'train.csv'
    test_path = data_dir / 'test.csv'
    building_path = data_dir / 'building_info.csv'
    
    train_df, test_df = load_data(train_path, test_path, building_path)
    
    # 1. ê¸°ì¡´ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    print("\n1. Testing Original Preprocessing...")
    train_fe, test_fe = engineer_features(train_df.copy(), test_df.copy())
    
    # í”¼ì²˜ ì¤€ë¹„
    drop_cols = ['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)', 'ì¼ì‹œ', 'num_date_time', 'datetime']
    feature_cols = [c for c in train_fe.columns if c not in drop_cols and c in test_fe.columns]
    
    X_orig = train_fe[feature_cols].copy()
    y_orig = train_fe['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
    
    # ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©
    categorical_cols = ['ê±´ë¬¼ë²ˆí˜¸', 'building_type']
    for col in categorical_cols:
        if col in X_orig.columns:
            le = LabelEncoder()
            X_orig[col] = le.fit_transform(X_orig[col].astype(str))
    
    # ê°ì²´ íƒ€ì… ì²˜ë¦¬
    for col in X_orig.columns:
        if X_orig[col].dtype == 'object':
            le = LabelEncoder()
            X_orig[col] = le.fit_transform(X_orig[col].astype(str))
    
    # ê°„ë‹¨í•œ ì‹œê³„ì—´ ë¶„í•  (ë§ˆì§€ë§‰ 7ì¼)
    cutoff = pd.Timestamp('2024-08-18')
    train_mask = train_fe['datetime'] < cutoff
    val_mask = ~train_mask
    
    X_train_orig = X_orig.loc[train_mask]
    y_train_orig = y_orig.loc[train_mask]
    X_val_orig = X_orig.loc[val_mask]
    y_val_orig = y_orig.loc[val_mask]
    
    # XGBoost ëª¨ë¸ í›ˆë ¨
    model_orig = xgb.XGBRegressor(
        max_depth=6,
        n_estimators=100,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
        learning_rate=0.1,
        random_state=42,
        verbosity=0
    )
    
    model_orig.fit(X_train_orig, y_train_orig)
    y_pred_orig = model_orig.predict(X_val_orig)
    smape_orig = smape(y_val_orig.values, y_pred_orig)
    
    print(f"Original Preprocessing SMAPE: {smape_orig:.4f}")
    
    # 2. ê°œì„ ëœ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    print("\n2. Testing Improved Preprocessing...")
    preprocessor = ImprovedPreprocessor()
    X_improved, X_test_improved, y_improved = preprocessor.fit_transform(train_df, test_df)
    
    # ê°™ì€ ë¶„í•  ê¸°ì¤€ ì ìš©
    train_processed, _ = engineer_features(train_df.copy(), test_df.copy())
    train_mask_improved = train_processed['datetime'] < cutoff
    val_mask_improved = ~train_mask_improved
    
    X_train_improved = X_improved.loc[train_mask_improved]
    y_train_improved = y_improved.loc[train_mask_improved]
    X_val_improved = X_improved.loc[val_mask_improved]
    y_val_improved = y_improved.loc[val_mask_improved]
    
    # XGBoost ëª¨ë¸ í›ˆë ¨
    model_improved = xgb.XGBRegressor(
        max_depth=6,
        n_estimators=100,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
        learning_rate=0.1,
        random_state=42,
        verbosity=0
    )
    
    model_improved.fit(X_train_improved, y_train_improved)
    y_pred_improved = model_improved.predict(X_val_improved)
    
    # ë¡œê·¸ ë³€í™˜ ì—­ë³€í™˜
    y_val_original = preprocessor.inverse_transform_target(y_val_improved)
    y_pred_original = preprocessor.inverse_transform_target(y_pred_improved)
    
    smape_improved = smape(y_val_original.values, y_pred_original)
    
    print(f"Improved Preprocessing SMAPE: {smape_improved:.4f}")
    
    # 3. ê²°ê³¼ ë¹„êµ
    print("\n" + "=" * 60)
    print("COMPARISON RESULTS")
    print("=" * 60)
    
    improvement = (smape_orig - smape_improved) / smape_orig * 100
    
    print(f"Original SMAPE:   {smape_orig:.4f}")
    print(f"Improved SMAPE:   {smape_improved:.4f}")
    print(f"Improvement:      {improvement:+.2f}%")
    
    if improvement > 0:
        print("âœ… Improved preprocessing shows better performance!")
    else:
        print("âŒ Original preprocessing performs better")
    
    # 4. í”¼ì²˜ ì¤‘ìš”ë„ ë¹„êµ
    print(f"\nFeature count comparison:")
    print(f"Original features: {X_orig.shape[1]}")
    print(f"Improved features: {X_improved.shape[1]}")
    
    # 5. ê°„ë‹¨í•œ ì‹œê°í™” ì •ë³´
    print(f"\nTarget transformation effect:")
    print(f"Original target mean: {y_orig.mean():.2f}, std: {y_orig.std():.2f}")
    print(f"Improved target mean: {y_improved.mean():.2f}, std: {y_improved.std():.2f}")
    
    return {
        'original_smape': smape_orig,
        'improved_smape': smape_improved,
        'improvement_pct': improvement,
        'original_features': X_orig.shape[1],
        'improved_features': X_improved.shape[1]
    }


if __name__ == "__main__":
    results = quick_test()
    print(f"\nğŸ¯ Quick test completed!")
    
    if results['improvement_pct'] > 0:
        print(f"ğŸš€ Improved preprocessing is {results['improvement_pct']:.2f}% better!")
    else:
        print(f"âš ï¸  Original preprocessing is {abs(results['improvement_pct']):.2f}% better")