#!/usr/bin/env python3
"""
Simple improvements to the original high-performance solution
ê¸°ì¡´ 7-8 SMAPE ì„±ëŠ¥ì„ 5-6ìœ¼ë¡œ ê°œì„ í•˜ê¸° ìœ„í•œ ê°„ë‹¨í•œ ê°œì„ ì‚¬í•­ë“¤
"""

import pandas as pd
import numpy as np
from pathlib import Path
import xgboost as xgb
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import make_scorer
import warnings
warnings.filterwarnings('ignore')

# ì›ë³¸ í•¨ìˆ˜ë“¤ import
from solution_backup import load_data, engineer_features, smape

def simple_improvements():
    """ê¸°ì¡´ ê³ ì„±ëŠ¥ ì†”ë£¨ì…˜ì— ê°„ë‹¨í•œ ê°œì„ ì‚¬í•­ë§Œ ì ìš©."""
    print("=" * 60)
    print("SIMPLE IMPROVEMENTS FOR 7-8 â†’ 5-6 SMAPE")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë“œ (ì›ë³¸ ë°©ì‹)
    print("1. Loading data with original method...")
    base_dir = Path('../data')
    train_path = base_dir / 'train.csv'
    test_path = base_dir / 'test.csv'
    building_path = base_dir / 'building_info.csv'
    
    train_df, test_df = load_data(train_path, test_path, building_path)
    train_fe, test_fe = engineer_features(train_df, test_df)
    
    print(f"   Data loaded: Train {train_fe.shape}, Test {test_fe.shape}")
    
    # 2. ê¸°ì¡´ í”¼ì²˜ì— ëª‡ ê°€ì§€ë§Œ ì¶”ê°€
    print("2. Adding minimal feature improvements...")
    
    for df in [train_fe, test_fe]:
        # ê°„ë‹¨í•œ ì‹œê°„ í”¼ì²˜ ì¶”ê°€
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        
        # ì˜¨ë„ êµ¬ê°„ë³„ í”¼ì²˜
        df['temp_category'] = pd.cut(df['temp'], bins=5, labels=['very_cold', 'cold', 'mild', 'warm', 'hot'])
        
        # ê±´ë¬¼ë³„ íš¨ìœ¨ì„± ê°„ë‹¨ ì§€í‘œ
        df['efficiency_score'] = (df['pv_capacity'] + 1) / (df['total_area'] + 1) * 1000
    
    print(f"   Features added: {train_fe.shape[1]} total features")
    
    # 3. ëª¨ë¸ ì„¤ì • (ì›ë³¸ì—ì„œ ì•½ê°„ë§Œ ì¡°ì •)
    print("3. Training improved model...")
    
    # í”¼ì²˜ ì¤€ë¹„
    feature_cols = [col for col in train_fe.columns 
                   if col not in ['num_date_time', 'ê±´ë¬¼ë²ˆí˜¸', 'ì¼ì‹œ', 'datetime', 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']]
    
    X = train_fe[feature_cols]
    y = train_fe['ì „ë ¥ì†Œë¹„ëŸ‰(kWh)']
    X_test = test_fe[feature_cols]
    
    # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (ì›ë³¸ê³¼ ë™ì¼)
    categorical_features = ['building_type', 'temp_category']
    categorical_transformer = OneHotEncoder(handle_unknown='ignore', drop='first')
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', categorical_transformer, categorical_features)
        ],
        remainder='passthrough'
    )
    
    # ì›ë³¸ ëª¨ë¸ì—ì„œ ì•½ê°„ë§Œ ì¡°ì • (ê³¼ìµœì í™” ë°©ì§€)
    model = xgb.XGBRegressor(
        max_depth=10,  # 12 â†’ 10 (ì•½ê°„ ë‹¨ìˆœí™”)
        n_estimators=1200,  # 1000 â†’ 1200 (ì•½ê°„ ì¦ê°€)
        learning_rate=0.025,  # 0.03 â†’ 0.025 (ë” ì •êµí•˜ê²Œ)
        subsample=0.85,  # 0.8 â†’ 0.85
        colsample_bytree=0.85,  # 0.8 â†’ 0.85
        reg_alpha=0.1,  # 0.0 â†’ 0.1 (ì•½ê°„ì˜ ì •ê·œí™”)
        reg_lambda=1.5,  # 1.0 â†’ 1.5 (ë” ê°•í•œ ì •ê·œí™”)
        objective='reg:squarederror',
        tree_method='hist',  # CPU ì‚¬ìš© (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
        random_state=42,
    )
    
    pipeline = Pipeline(steps=[('preprocess', preprocessor), ('model', model)])
    
    # 4. ê²€ì¦ (ì›ë³¸ ë°©ì‹)
    cutoff = pd.Timestamp('2024-08-18')
    train_mask = train_fe['datetime'] < cutoff
    val_mask = ~train_mask
    X_train, y_train = X.loc[train_mask], y.loc[train_mask]
    X_val, y_val = X.loc[val_mask], y.loc[val_mask]
    
    # í•™ìŠµ ë° ê²€ì¦
    pipeline.fit(X_train, y_train)
    val_pred = pipeline.predict(X_val)
    val_smape = smape(y_val.values, val_pred)
    
    print(f"4. Validation SMAPE: {val_smape:.4f}")
    
    # 5. ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ë° ì˜ˆì¸¡
    print("5. Final training and prediction...")
    pipeline.fit(X, y)
    test_pred = pipeline.predict(X_test)
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    submission = test_fe[['num_date_time']].copy()
    submission['answer'] = test_pred
    submission.to_csv('submission_simple_improved.csv', index=False)
    
    print(f"âœ… Simple improvement completed!")
    print(f"ğŸ“Š Validation SMAPE: {val_smape:.4f}")
    print(f"ğŸ’¾ Submission saved: submission_simple_improved.csv")
    print(f"ğŸ¯ Target: Improve 7-8 SMAPE â†’ 5-6 SMAPE")
    
    return val_smape

if __name__ == "__main__":
    result = simple_improvements()