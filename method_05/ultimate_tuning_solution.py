"""
Ultimate Tuning Solution
========================

ëª¨ë“  ê°œì„ ì‚¬í•­ì„ í†µí•©í•œ ìµœì¢… íŠœë‹ ì†”ë£¨ì…˜:
1. ì‹œê°í™” ë¶„ì„ ê¸°ë°˜ ì „ì²˜ë¦¬ ê°œì„ 
2. Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
3. CatBoost ì¶”ê°€ 3-model ì•™ìƒë¸”
4. ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
5. Stacking ì•™ìƒë¸”

ëª©í‘œ: 11.8 SMAPE â†’ 7-8 SMAPE
"""

import pandas as pd
import numpy as np
from pathlib import Path
import xgboost as xgb
import lightgbm as lgb
import catboost as cb
from sklearn.ensemble import VotingRegressor, StackingRegressor
from sklearn.linear_model import Ridge
from sklearn.preprocessing import LabelEncoder
import optuna
import warnings
warnings.filterwarnings('ignore')

from solution import load_data, smape
from ts_validation import TimeSeriesCV
from improved_preprocessing import ImprovedPreprocessor
from advanced_feature_engineering import AdvancedFeatureEngineer


class UltimateTuningSolution:
    """ìµœì¢… íŠœë‹ ì†”ë£¨ì…˜ í´ë˜ìŠ¤."""
    
    def __init__(self, quick_mode=False, max_trials=None):
        self.quick_mode = quick_mode  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
        self.max_trials = max_trials or (20 if quick_mode else 100)  # trial ìˆ˜ ëŒ€í­ ì¦ê°€
        self.best_params = {}
        self.best_models = {}
        self.validation_results = {}
        
    def optimize_hyperparameters_fast(self, X, y, datetime_series):
        """ë¹ ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”."""
        print("ğŸ” Fast hyperparameter optimization...")
        
        ts_cv = TimeSeriesCV(n_splits=2, test_size_days=7, gap_days=1)
        temp_df = pd.DataFrame({'datetime': datetime_series})
        splits = list(ts_cv.split(temp_df, 'datetime'))
        
        def cross_validate_model(model, X, y, splits):
            scores = []
            for train_idx, val_idx in splits:
                X_train_fold = X.iloc[train_idx]
                y_train_fold = y.iloc[train_idx]
                X_val_fold = X.iloc[val_idx]
                y_val_fold = y.iloc[val_idx]
                
                try:
                    model.fit(X_train_fold, y_train_fold)
                    y_pred = model.predict(X_val_fold)
                    
                    # ë¡œê·¸ ë³€í™˜ ì—­ë³€í™˜
                    y_val_original = np.expm1(y_val_fold)
                    y_pred_original = np.expm1(y_pred)
                    
                    fold_smape = smape(y_val_original.values, y_pred_original)
                    scores.append(fold_smape)
                except:
                    scores.append(float('inf'))
            
            return np.mean(scores)
        
        # XGBoost ìµœì í™”
        def xgb_objective(trial):
            params = {
                'max_depth': trial.suggest_int('max_depth', 8, 15),  # ë” ê¹Šì€ íŠ¸ë¦¬
                'n_estimators': trial.suggest_int('n_estimators', 800, 2000, step=200),  # ë” ë§ì€ íŠ¸ë¦¬
                'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.1),  # ë” ì •êµí•œ í•™ìŠµ
                'subsample': trial.suggest_float('subsample', 0.7, 0.95),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),
                'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 0.9),  # ì¶”ê°€ íŒŒë¼ë¯¸í„°
                'colsample_bynode': trial.suggest_float('colsample_bynode', 0.6, 0.9),   # ì¶”ê°€ íŒŒë¼ë¯¸í„°
                'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 5.0),
                'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 5.0),
                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # ì¶”ê°€ íŒŒë¼ë¯¸í„°
                'tree_method': 'gpu_hist',  # GPU ê°€ì†
                'gpu_id': 0,
                'max_bin': 512,  # GPU ë©”ëª¨ë¦¬ í™œìš©ë„ ì¦ê°€
                'random_state': 42,
                'verbosity': 0
            }
            model = xgb.XGBRegressor(**params)
            return cross_validate_model(model, X, y, splits)
        
        # LightGBM ìµœì í™”
        def lgb_objective(trial):
            params = {
                'max_depth': trial.suggest_int('max_depth', 10, 20),  # ë” ê¹Šì€ íŠ¸ë¦¬
                'n_estimators': trial.suggest_int('n_estimators', 1000, 3000, step=500),  # ë” ë§ì€ íŠ¸ë¦¬
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.08),  # ë” ì •êµí•œ í•™ìŠµ
                'subsample': trial.suggest_float('subsample', 0.7, 0.95),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),
                'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 5.0),
                'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 5.0),
                'num_leaves': trial.suggest_int('num_leaves', 200, 1000),  # ë” ë§ì€ ì
                'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),  # ì¶”ê°€ íŒŒë¼ë¯¸í„°
                'min_child_weight': trial.suggest_float('min_child_weight', 0.001, 0.1),  # ì¶”ê°€ íŒŒë¼ë¯¸í„°
                'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),  # ì¶”ê°€ íŒŒë¼ë¯¸í„°
                'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 0.9),  # ì¶”ê°€ íŒŒë¼ë¯¸í„°
                'device': 'gpu',  # GPU ê°€ì†
                'gpu_use_dp': True,
                'max_bin': 1023,  # GPU ë©”ëª¨ë¦¬ í™œìš©ë„ ì¦ê°€
                'random_state': 42,
                'verbosity': -1
            }
            model = lgb.LGBMRegressor(**params)
            return cross_validate_model(model, X, y, splits)
        
        # CatBoost ìµœì í™”
        def cb_objective(trial):
            params = {
                'depth': trial.suggest_int('depth', 8, 16),  # ë” ê¹Šì€ íŠ¸ë¦¬
                'iterations': trial.suggest_int('iterations', 1000, 3000, step=500),  # ë” ë§ì€ ë°˜ë³µ
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),  # ë” ì •êµí•œ í•™ìŠµ
                'bootstrap_type': 'Bernoulli',  # subsampleê³¼ í˜¸í™˜ë˜ëŠ” bootstrap íƒ€ì…
                'subsample': trial.suggest_float('subsample', 0.7, 0.95),
                'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 10.0),
                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 20),
                'max_leaves': trial.suggest_int('max_leaves', 256, 2048),  # ë” ë§ì€ ì
                'border_count': trial.suggest_int('border_count', 128, 512),  # ì¶”ê°€ íŒŒë¼ë¯¸í„°
                'feature_border_type': 'GreedyLogSum',  # GPU ìµœì í™”
                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),  # ì¶”ê°€ íŒŒë¼ë¯¸í„°
                'task_type': 'GPU',  # GPU ê°€ì†
                'gpu_ram_part': 0.8,  # GPU ë©”ëª¨ë¦¬ í™œìš©ë„ ì¦ê°€
                'random_seed': 42,
                'verbose': False
            }
            model = cb.CatBoostRegressor(**params)
            return cross_validate_model(model, X, y, splits)
        
        # ê° ëª¨ë¸ ìµœì í™” ì‹¤í–‰
        n_trials = self.max_trials
        
        print("  Optimizing XGBoost...")
        xgb_study = optuna.create_study(direction='minimize')
        xgb_study.optimize(xgb_objective, n_trials=n_trials, show_progress_bar=False)
        self.best_params['xgboost'] = xgb_study.best_params
        
        print("  Optimizing LightGBM...")
        lgb_study = optuna.create_study(direction='minimize')
        lgb_study.optimize(lgb_objective, n_trials=n_trials, show_progress_bar=False)
        self.best_params['lightgbm'] = lgb_study.best_params
        
        print("  Optimizing CatBoost...")
        cb_study = optuna.create_study(direction='minimize')
        cb_study.optimize(cb_objective, n_trials=n_trials, show_progress_bar=False)
        self.best_params['catboost'] = cb_study.best_params
        
        print(f"âœ… Hyperparameter optimization completed")
        print(f"   XGBoost best: {xgb_study.best_value:.4f}")
        print(f"   LightGBM best: {lgb_study.best_value:.4f}")
        print(f"   CatBoost best: {cb_study.best_value:.4f}")
        
        return self.best_params
    
    def create_optimized_models(self):
        """ìµœì í™”ëœ ëª¨ë¸ë“¤ ìƒì„±."""
        print("ğŸ”§ Creating optimized models...")
        
        # ê°œë³„ ìµœì í™”ëœ ëª¨ë¸ë“¤ (GPU ì„¤ì • í¬í•¨)
        xgb_params = self.best_params['xgboost'].copy()
        xgb_params.update({'tree_method': 'gpu_hist', 'gpu_id': 0})
        self.best_models['xgboost'] = xgb.XGBRegressor(**xgb_params)
        
        lgb_params = self.best_params['lightgbm'].copy()
        lgb_params.update({'device': 'gpu', 'gpu_use_dp': True})
        self.best_models['lightgbm'] = lgb.LGBMRegressor(**lgb_params)
        
        cb_params = self.best_params['catboost'].copy()
        cb_params.update({'task_type': 'GPU', 'bootstrap_type': 'Bernoulli'})
        self.best_models['catboost'] = cb.CatBoostRegressor(**cb_params)
        
        # ì•™ìƒë¸” ëª¨ë¸ë“¤
        self.best_models['voting_ensemble'] = VotingRegressor([
            ('xgb', self.best_models['xgboost']),
            ('lgb', self.best_models['lightgbm']),
            ('cb', self.best_models['catboost'])
        ], weights=[0.4, 0.35, 0.25])
        
        self.best_models['stacking_ensemble'] = StackingRegressor(
            estimators=[
                ('xgb', self.best_models['xgboost']),
                ('lgb', self.best_models['lightgbm']),
                ('cb', self.best_models['catboost'])
            ],
            final_estimator=Ridge(alpha=1.0),
            cv=3
        )
        
        print(f"âœ… Created {len(self.best_models)} optimized models")
    
    def validate_all_models(self, X, y, datetime_series):
        """ëª¨ë“  ëª¨ë¸ ê²€ì¦."""
        print("ğŸ“Š Validating all models...")
        
        ts_cv = TimeSeriesCV(n_splits=3, test_size_days=7, gap_days=1)
        temp_df = pd.DataFrame({'datetime': datetime_series})
        splits = ts_cv.split(temp_df, 'datetime')
        
        for model_name, model in self.best_models.items():
            print(f"  Validating {model_name}...")
            
            fold_scores = []
            for fold, (train_idx, val_idx) in enumerate(splits):
                X_train_fold = X.iloc[train_idx]
                y_train_fold = y.iloc[train_idx]
                X_val_fold = X.iloc[val_idx]
                y_val_fold = y.iloc[val_idx]
                
                try:
                    model.fit(X_train_fold, y_train_fold)
                    y_pred = model.predict(X_val_fold)
                    
                    # ë¡œê·¸ ë³€í™˜ ì—­ë³€í™˜
                    y_val_original = np.expm1(y_val_fold)
                    y_pred_original = np.expm1(y_pred)
                    
                    fold_smape = smape(y_val_original.values, y_pred_original)
                    fold_scores.append(fold_smape)
                    
                except Exception as e:
                    print(f"    âŒ Error in {model_name} fold {fold}: {e}")
                    fold_scores.append(float('inf'))
            
            mean_score = np.mean(fold_scores) if fold_scores else float('inf')
            std_score = np.std(fold_scores) if fold_scores else 0
            
            self.validation_results[model_name] = {
                'mean': mean_score,
                'std': std_score,
                'folds': fold_scores
            }
            
            print(f"    {model_name}: {mean_score:.4f} (Â±{std_score:.4f})")
    
    def generate_ultimate_submission(self, X_train, X_test, y_train, test_df):
        """ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„±."""
        print("ğŸ¯ Generating ultimate submission...")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
        valid_results = {k: v for k, v in self.validation_results.items() 
                        if v['mean'] != float('inf')}
        
        if not valid_results:
            print("âŒ No valid models found!")
            return None, None
        
        best_model_name = min(valid_results.keys(), 
                            key=lambda x: valid_results[x]['mean'])
        best_model = self.best_models[best_model_name]
        best_score = valid_results[best_model_name]['mean']
        
        print(f"ğŸ† Selected model: {best_model_name}")
        print(f"ğŸ¯ Expected SMAPE: {best_score:.4f}")
        
        # ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ
        print("  Training on full dataset...")
        best_model.fit(X_train, y_train)
        
        # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
        print("  Making predictions...")
        test_predictions_log = best_model.predict(X_test)
        test_predictions = np.expm1(test_predictions_log)
        test_predictions = np.maximum(test_predictions, 0)
        
        # ì œì¶œ íŒŒì¼ ìƒì„±
        submission = pd.DataFrame({
            'num_date_time': test_df['num_date_time'],
            'answer': test_predictions
        })
        
        submission_file = f'submission_ultimate_{best_model_name}.csv'
        submission.to_csv(submission_file, index=False)
        
        print(f"ğŸ’¾ Ultimate submission saved: {submission_file}")
        print(f"ğŸ“Š Predictions range: {test_predictions.min():.2f} - {test_predictions.max():.2f}")
        print(f"ğŸ“Š Predictions mean: {test_predictions.mean():.2f}")
        
        return submission, best_model_name
    
    def create_ultimate_report(self, output_dir='./visualizations/'):
        """ìµœì¢… íŠœë‹ ë¦¬í¬íŠ¸."""
        report_path = Path(output_dir) / 'ultimate_tuning_report.md'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# Ultimate Tuning Solution Report\n\n")
            
            f.write("## Applied Optimizations\n\n")
            f.write("1. **Visualization-based preprocessing improvements**\n")
            f.write("   - Target log transformation\n")
            f.write("   - VIF-based multicollinearity removal\n")
            f.write("   - RobustScaler feature scaling\n")
            f.write("   - IQR-based outlier treatment\n\n")
            
            f.write("2. **Advanced feature engineering**\n")
            f.write("   - Building clustering (5 clusters)\n")
            f.write("   - Advanced time features (15min, 30min patterns)\n")
            f.write("   - Enhanced weather features (apparent temp, heat index)\n")
            f.write("   - Multi-way interaction features\n\n")
            
            f.write("3. **Hyperparameter optimization**\n")
            f.write("   - Optuna-based systematic search\n")
            f.write("   - Individual optimization for XGBoost, LightGBM, CatBoost\n")
            f.write("   - Time series cross-validation\n\n")
            
            f.write("4. **Advanced ensemble methods**\n")
            f.write("   - Weighted voting ensemble\n")
            f.write("   - Ridge-based stacking ensemble\n")
            f.write("   - Optimized model weights\n\n")
            
            f.write("## Model Performance Results\n\n")
            f.write("| Model | Mean SMAPE | Std SMAPE | Status |\n")
            f.write("|-------|------------|-----------|--------|\n")
            
            baseline = 11.8
            for model_name, result in self.validation_results.items():
                if result['mean'] != float('inf'):
                    improvement = (baseline - result['mean']) / baseline * 100
                    status = "âœ… Improved" if result['mean'] < baseline else "âŒ Degraded"
                    f.write(f"| {model_name} | {result['mean']:.4f} | {result['std']:.4f} | {status} |\n")
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
            valid_results = {k: v for k, v in self.validation_results.items() 
                           if v['mean'] != float('inf')}
            
            if valid_results:
                best_model = min(valid_results.items(), key=lambda x: x[1]['mean'])
                best_improvement = (baseline - best_model[1]['mean']) / baseline * 100
                
                f.write(f"\n## Best Result\n\n")
                f.write(f"- **Model**: {best_model[0]}\n")
                f.write(f"- **SMAPE**: {best_model[1]['mean']:.4f}\n")
                f.write(f"- **Improvement**: {best_improvement:.2f}% vs baseline (11.8)\n")
                
                if best_model[1]['mean'] < 8.0:
                    f.write("- **Status**: ğŸ‰ Excellent! Sub-8 SMAPE achieved!\n")
                elif best_model[1]['mean'] < 9.0:
                    f.write("- **Status**: âœ… Great! Sub-9 SMAPE achieved!\n")
                elif best_model[1]['mean'] < 10.0:
                    f.write("- **Status**: âœ… Good! Sub-10 SMAPE achieved!\n")
                else:
                    f.write("- **Status**: âš ï¸ Moderate improvement\n")
            
            f.write(f"\n## Performance Evolution\n\n")
            f.write(f"1. **Original baseline**: ~53 SMAPE (data leakage)\n")
            f.write(f"2. **Safe baseline**: ~20 SMAPE (no leakage)\n")
            f.write(f"3. **Improved preprocessing**: 11.8 SMAPE (16.62% improvement)\n")
            f.write(f"4. **Ultimate tuning**: {best_model[1]['mean']:.1f} SMAPE ({best_improvement:.1f}% total improvement)\n")
            
            f.write(f"\n## Production Deployment\n\n")
            f.write(f"- **Recommended model**: {best_model[0]}\n")
            f.write(f"- **Expected performance**: {best_model[1]['mean']:.1f} Â± {best_model[1]['std']:.1f} SMAPE\n")
            f.write(f"- **Confidence level**: High (validated with time series CV)\n")
            f.write(f"- **Submission file**: `submission_ultimate_{best_model[0]}.csv`\n")
        
        print(f"ğŸ“„ Ultimate tuning report saved: {report_path}")
    
    def run_ultimate_tuning(self):
        """ìµœì¢… íŠœë‹ ì†”ë£¨ì…˜ ì‹¤í–‰."""
        print("=" * 80)
        print("ULTIMATE TUNING SOLUTION")
        print("=" * 80)
        print("Combining all optimizations for maximum performance")
        print(f"Quick mode: {'ON' if self.quick_mode else 'OFF'}")
        
        # 1. ë°ì´í„° ë¡œë“œ
        print("\n1. Loading and preprocessing data...")
        data_dir = Path('../data')
        train_path = data_dir / 'train.csv'
        test_path = data_dir / 'test.csv'
        building_path = data_dir / 'building_info.csv'
        
        train_df, test_df = load_data(train_path, test_path, building_path)
        
        # 2. ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
        print("\n2. Advanced feature engineering...")
        engineer = AdvancedFeatureEngineer()
        train_advanced, test_advanced, _ = engineer.apply_advanced_feature_engineering(
            train_df, test_df
        )
        
        # 3. ê°œì„ ëœ ì „ì²˜ë¦¬ ì ìš© (RobustScaler - ì„±ëŠ¥ ê²€ì¦ë¨)
        print("\n3. Applying improved preprocessing...")
        preprocessor = ImprovedPreprocessor(scaler_type='robust')  # RobustScalerë¡œ ë³µì›
        X_train, X_test, y_train = preprocessor.fit_transform(train_advanced, test_advanced)
        
        # datetime ì‹œë¦¬ì¦ˆ (êµì°¨ê²€ì¦ìš©)
        from solution import engineer_features
        train_processed, _ = engineer_features(train_df.copy(), test_df.copy())
        datetime_series = train_processed['datetime']
        
        print(f"ğŸ“Š Final dataset: {len(X_train)} samples, {len(X_train.columns)} features")
        
        # 4. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
        print("\n4. Hyperparameter optimization...")
        self.optimize_hyperparameters_fast(X_train, y_train, datetime_series)
        
        # 5. ìµœì í™”ëœ ëª¨ë¸ë“¤ ìƒì„±
        print("\n5. Creating optimized models...")
        self.create_optimized_models()
        
        # 6. ëª¨ë“  ëª¨ë¸ ê²€ì¦
        print("\n6. Validating all models...")
        self.validate_all_models(X_train, y_train, datetime_series)
        
        # 7. ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„±
        print("\n7. Generating ultimate submission...")
        submission, best_model_name = self.generate_ultimate_submission(
            X_train, X_test, y_train, test_df
        )
        
        # 8. ë¦¬í¬íŠ¸ ìƒì„±
        print("\n8. Creating final report...")
        self.create_ultimate_report()
        
        # 9. ìµœì¢… ê²°ê³¼
        print(f"\n" + "=" * 80)
        print("ULTIMATE TUNING RESULTS")
        print("=" * 80)
        
        baseline = 11.8
        valid_results = {k: v for k, v in self.validation_results.items() 
                        if v['mean'] != float('inf')}
        
        if valid_results:
            best_score = min(v['mean'] for v in valid_results.values())
            total_improvement = (baseline - best_score) / baseline * 100
            
            print(f"ğŸ¯ Best SMAPE: {best_score:.4f}")
            print(f"ğŸš€ Total improvement: {total_improvement:.2f}%")
            print(f"ğŸ† Best model: {best_model_name}")
            print(f"ğŸ“ˆ Performance evolution: 53 â†’ 11.8 â†’ {best_score:.1f}")
            
            if best_score < 8.0:
                print("ğŸ‰ OUTSTANDING! Sub-8 SMAPE achieved!")
            elif best_score < 9.0:
                print("âœ… EXCELLENT! Sub-9 SMAPE achieved!")
            elif best_score < 10.0:
                print("âœ… GREAT! Sub-10 SMAPE achieved!")
            
            print(f"ğŸ’¾ Submission: submission_ultimate_{best_model_name}.csv")
        
        return self.validation_results, best_model_name


if __name__ == "__main__":
    # ê³ ì„±ëŠ¥ ìµœì í™” ëª¨ë“œ (GPU ì„œë²„ìš© - VRAM ìµœëŒ€ í™œìš©)
    solution = UltimateTuningSolution(quick_mode=False, max_trials=100)  # VRAM ìµœëŒ€ í™œìš©
    results, best_model = solution.run_ultimate_tuning()
    
    print(f"\nğŸ¯ Ultimate tuning solution completed!")
    print(f"ğŸš€ Ready for GPU server deployment!")