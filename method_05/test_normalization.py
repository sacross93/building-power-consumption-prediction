#!/usr/bin/env python3
"""
ì •ê·œí™” ë°©ë²•ë“¤ì˜ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, QuantileTransformer
from sklearn.model_selection import TimeSeriesSplit
import xgboost as xgb
from advanced_feature_engineering import AdvancedFeatureEngineer
from improved_preprocessing import ImprovedPreprocessor
import warnings
warnings.filterwarnings('ignore')

def smape_score(y_true, y_pred):
    """SMAPE ê³„ì‚°."""
    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))

def test_normalization_methods():
    """ë‹¤ì–‘í•œ ì •ê·œí™” ë°©ë²• í…ŒìŠ¤íŠ¸."""
    print("=" * 60)
    print("NORMALIZATION METHODS COMPARISON")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë“œ ë° ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    print("1. Loading data and applying advanced FE...")
    from solution import load_data
    data_dir = Path('../data')
    train_path = data_dir / 'train.csv'
    test_path = data_dir / 'test.csv'
    building_path = data_dir / 'building_info.csv'
    
    train_df, test_df = load_data(train_path, test_path, building_path)
    
    # ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì ìš©
    engineer = AdvancedFeatureEngineer()
    train_advanced, test_advanced, _ = engineer.apply_advanced_feature_engineering(
        train_df, test_df
    )
    
    print(f"   Advanced FE completed: {train_advanced.shape[1]} features")
    
    # 2. ë² ì´ìŠ¤ë¼ì¸ (í˜„ìž¬ RobustScaler)
    print("\n2. Testing normalization methods...")
    
    scalers = {
        'RobustScaler (Current)': RobustScaler(),
        'StandardScaler': StandardScaler(),
        'MinMaxScaler': MinMaxScaler(),
        'QuantileTransformer': QuantileTransformer(n_quantiles=100, random_state=42)
    }
    
    results = {}
    
    for scaler_name, scaler in scalers.items():
        print(f"\n   Testing {scaler_name}...")
        
        # ImprovedPreprocessorì— scaler ì ìš©
        preprocessor = ImprovedPreprocessor()
        preprocessor.scaler = scaler  # scaler êµì²´
        
        X_train, X_test, y_train = preprocessor.fit_transform(
            train_advanced.copy(), test_advanced.copy()
        )
        
        # ë¹ ë¥¸ XGBoost ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
        model = xgb.XGBRegressor(
            objective='reg:squarederror',
            n_estimators=100,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
            max_depth=6,
            learning_rate=0.1,
            random_state=42,
            n_jobs=-1
        )
        
        # ì‹œê³„ì—´ êµì°¨ê²€ì¦
        tscv = TimeSeriesSplit(n_splits=3)
        cv_scores = []
        
        for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train)):
            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]
            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]
            
            model.fit(X_tr, y_tr)
            y_pred = model.predict(X_val)
            
            # ë¡œê·¸ ì—­ë³€í™˜
            y_val_orig = np.expm1(y_val)
            y_pred_orig = np.expm1(y_pred)
            
            smape = smape_score(y_val_orig, y_pred_orig)
            cv_scores.append(smape)
        
        avg_smape = np.mean(cv_scores)
        std_smape = np.std(cv_scores)
        results[scaler_name] = {'mean': avg_smape, 'std': std_smape}
        
        print(f"      SMAPE: {avg_smape:.3f} Â± {std_smape:.3f}")
    
    # 3. ê²°ê³¼ ì •ë¦¬
    print("\n" + "=" * 60)
    print("NORMALIZATION COMPARISON RESULTS")
    print("=" * 60)
    
    sorted_results = sorted(results.items(), key=lambda x: x[1]['mean'])
    
    for i, (method, score) in enumerate(sorted_results):
        status = "ðŸ¥‡ BEST" if i == 0 else f"#{i+1}"
        print(f"{status:>8} {method:<25} SMAPE: {score['mean']:.3f} Â± {score['std']:.3f}")
    
    best_method = sorted_results[0][0]
    improvement = results['RobustScaler (Current)']['mean'] - sorted_results[0][1]['mean']
    
    print(f"\nðŸŽ¯ Best method: {best_method}")
    if improvement > 0:
        print(f"ðŸ“ˆ Improvement over current: -{improvement:.3f} SMAPE")
        print(f"ðŸ’¡ Recommendation: Switch to {best_method}")
    else:
        print(f"ðŸ“Š Current RobustScaler is optimal")
    
    return best_method, results

if __name__ == "__main__":
    best_method, results = test_normalization_methods()